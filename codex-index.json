[
  {
    "path": "weaves/frame/openstrand/architecture.md",
    "name": "architecture.md",
    "type": "file",
    "metadata": {
      "id": "3c3ac6d5-8cc2-4106-9f4a-4f6134c3d0b2",
      "slug": "openstrand-architecture",
      "title": "OpenStrand Architecture â€“ Condensed Overview",
      "summary": "A practical, implementation-focused overview of OpenStrand's architecture for ingestion and RAG.",
      "version": "1.0.0",
      "contentType": "reference",
      "difficulty": {
        "overall": "advanced",
        "cognitive": 8,
        "prerequisites": 5,
        "conceptual": 8
      },
      "taxonomy": {
        "subject": [
          "computing",
          "knowledge-systems"
        ],
        "topic": [
          "openstrand",
          "architecture"
        ],
        "subtopic": [
          "api",
          "pipelines",
          "metadata",
          "search",
          "embeddings"
        ],
        "concepts": [
          {
            "term": "strands",
            "weight": 0.8
          },
          {
            "term": "looms",
            "weight": 0.6
          },
          {
            "term": "weaves",
            "weight": 0.6
          },
          {
            "term": "knowledge-graph",
            "weight": 0.8
          },
          {
            "term": "ingestion",
            "weight": 0.7
          }
        ]
      },
      "relationships": [
        {
          "targetSlug": "openstrand-ingestion",
          "type": "follows",
          "strength": 0.7,
          "bidirectional": false
        }
      ],
      "publishing": {
        "status": "published",
        "license": "MIT"
      },
      "autoGenerated": {
        "keywords": [
          "openstrand",
          "architecture",
          "condensed",
          "overview",
          "practical",
          "implementation",
          "focused",
          "ingestion",
          "rag",
          "strand",
          "condenses",
          "short",
          "practitioner",
          "guide",
          "full"
        ],
        "phrases": [
          "openstrand architecture"
        ],
        "subjects": [],
        "topics": [],
        "difficulty": {
          "overall": "advanced",
          "cognitive": 8,
          "prerequisites": 5,
          "conceptual": 8
        },
        "confidence": {},
        "readingLevel": 0,
        "readabilityScore": 0,
        "statistics": {},
        "entities": {
          "people": [],
          "places": [],
          "organizations": [
            "RAG & Search",
            "(GitHub",
            "Governance & SEO"
          ],
          "topics": [
            "Governance & SEO",
            "(GitHub",
            "RAG & Search"
          ]
        },
        "lastIndexed": "2025-12-01T07:58:06.129Z"
      }
    },
    "validation": {
      "valid": true,
      "errors": [],
      "warnings": [],
      "suggestions": [
        "Consider adding tags: openstrand, architecture, condensed, overview, practical",
        "Auto-detected subjects: ",
        "Auto-detected topics: ",
        "Key phrases found: openstrand architecture"
      ]
    },
    "content": "\nThis strand condenses the OpenStrand Architecture into a short practitioner guide. For full details, see the comprehensive architecture document in the OpenStrand repo and related strands in this loom.\n\n## Key Ideas\n- Strands: atomic assets (docs, media, datasets); Looms: curated groups of strands (folders); Weaves: entire universes of content. No cross-weave edges.\n- Ingestion: parse frontmatter â†’ validate â†’ persist ECA â†’ index (text + vector) â†’ construct relations (within weave).\n- Retrieval: combine lexical + semantic + graph edges; re-rank with pedagogical and structural signals.\n- Pipelines: support multi-format content; normalize to Markdown + frontmatter; attach assets alongside strands.\n\n## Ingestion Mapping\n1. Read `weave.yaml` â†’ create workspace scope  \n2. Detect looms: any folder inside a weave is a loom (no `looms/` prefix needed)\n3. For each strand (markdown file):\n   - Extract frontmatter (id, slug, title, taxonomy, relationships)\n   - Store Markdown and assets\n   - Create edges only to strands in the same weave\n4. Build search index + embeddings\n\n## RAG & Search\n- Flat inverted index for fast client-side search (GitHub Pages).\n- Vector store for semantic similarity (server-side or local).\n- Graph traversal to suggest next-items within a loom.\n\n## Governance & SEO\n- Short executive summaries; single-topic strands; stable anchors; internal links between strands.\n- Controlled vocabulary in `tags/index.yaml`; CI validates tag usage and relationships.\n",
    "searchText": "openstrand architecture â€“ condensed overview a practical, implementation-focused overview of openstrand's architecture for ingestion and rag. openstrand architecture condensed overview practical implementation focused ingestion rag strand condenses short practitioner guide full openstrand architecture"
  },
  {
    "path": "weaves/frame/weave.yaml",
    "name": "weave.yaml",
    "type": "file",
    "metadata": {
      "slug": "frame",
      "title": "Frame",
      "description": "The Frame weave: documentation, architecture, and knowledge related to the Frame ecosystem. This weave is a self-contained universe; no relationships to strands outside of this weave.\n",
      "maintainedBy": "team@frame.dev",
      "license": "MIT",
      "tags": [
        "computing",
        "knowledge-systems",
        "rag"
      ],
      "summary": "slug: frame\ntitle: Frame\ndescription: >\n  The Frame weave: documentation, architecture, and knowledge related to the Frame ecosystem",
      "autoGenerated": {
        "keywords": [
          "frame",
          "knowledge",
          "description",
          "documentation",
          "ecosystem",
          "self",
          "contained",
          "universe",
          "maintainedby",
          "dev",
          "license",
          "mit",
          "computing",
          "systems",
          "slug"
        ],
        "phrases": [
          "slug frame",
          "frame title",
          "title frame",
          "frame description",
          "description frame",
          "frame weave",
          "weave documentation",
          "documentation architecture",
          "architecture knowledge",
          "knowledge related"
        ],
        "subjects": [],
        "topics": [],
        "difficulty": "intermediate",
        "confidence": {},
        "readingLevel": 0,
        "readabilityScore": 0,
        "statistics": {},
        "entities": {
          "people": [],
          "places": [],
          "organizations": [],
          "topics": []
        },
        "lastIndexed": "2025-12-01T07:58:06.147Z"
      }
    },
    "validation": {
      "valid": true,
      "errors": [],
      "warnings": [],
      "suggestions": [
        "Add unique ID (UUID recommended)",
        "Add version number (semver format)",
        "Consider adding relationships (requires, references, seeAlso)",
        "Auto-detected subjects: ",
        "Auto-detected topics: ",
        "Suggested difficulty: intermediate",
        "Key phrases found: slug frame, frame title, title frame"
      ]
    },
    "content": "slug: frame\ntitle: Frame\ndescription: >\n  The Frame weave: documentation, architecture, and knowledge related to the Frame ecosystem.\n  This weave is a self-contained universe; no relationships to strands outside of this weave.\nmaintainedBy: team@frame.dev\nlicense: MIT\ntags: [computing, knowledge-systems, rag]\n\n\n",
    "searchText": "frame slug: frame\ntitle: frame\ndescription: >\n  the frame weave: documentation, architecture, and knowledge related to the frame ecosystem frame knowledge description documentation ecosystem self contained universe maintainedby dev license mit computing systems slug slug frame frame title title frame frame description description frame frame weave weave documentation documentation architecture architecture knowledge knowledge related"
  },
  {
    "path": "weaves/wiki/architecture/overview.md",
    "name": "overview.md",
    "type": "file",
    "metadata": {
      "id": "8f4e7c3a-9b2d-4e1a-a5f6-1c8d9e0b2f3a",
      "slug": "codex-architecture-overview",
      "title": "Frame Codex Architecture Overview",
      "summary": "High-level architecture of Frame Codex: three-tier knowledge organization, SQL caching, static NLP, and automation",
      "version": "1.0.0",
      "contentType": "markdown",
      "difficulty": "intermediate",
      "taxonomy": {
        "subjects": [
          "technology",
          "knowledge"
        ],
        "topics": [
          "architecture",
          "getting-started"
        ]
      },
      "tags": [
        "architecture",
        "weave",
        "loom",
        "strand",
        "sql-cache",
        "nlp"
      ],
      "relationships": {
        "references": [
          "sql-cache-architecture",
          "nlp-pipeline",
          "automation-workflows"
        ]
      },
      "publishing": {
        "status": "published"
      },
      "autoGenerated": {
        "keywords": [
          "codex",
          "fabric",
          "files",
          "auto",
          "sql",
          "analysis",
          "frame",
          "organization",
          "caching",
          "automation",
          "metadata",
          "structure",
          "validation",
          "quality",
          "loom"
        ],
        "phrases": [
          "frame codex",
          "loom folder",
          "strand markdown",
          "markdown file",
          "static nlp",
          "codex architecture",
          "architecture overview",
          "tier knowledge",
          "knowledge organization",
          "cross weave"
        ],
        "subjects": [
          "technology",
          "knowledge"
        ],
        "topics": [
          "architecture",
          "getting-started"
        ],
        "difficulty": "intermediate",
        "confidence": {},
        "readingLevel": 0,
        "readabilityScore": 0,
        "statistics": {},
        "entities": {
          "people": [
            "- Rich"
          ],
          "places": [],
          "organizations": [
            "AI systems",
            "**GitHub",
            "Tech & CS",
            ".github/"
          ],
          "topics": [
            ".github/",
            "Tech & CS",
            "**GitHub",
            "AI systems",
            "- Rich"
          ]
        },
        "lastIndexed": "2025-12-01T07:58:06.278Z"
      }
    },
    "validation": {
      "valid": true,
      "errors": [],
      "warnings": [],
      "suggestions": [
        "Key phrases found: frame codex, loom folder, strand markdown"
      ]
    },
    "content": "\n# Frame Codex Architecture Overview\n\nFrame Codex is a structured, version-controlled knowledge repository designed as the canonical source of truth for AI systems and human learners.\n\n## Core Concepts\n\n### Four-Tier Knowledge Organization\n\n```\nFabric (Whole Codex)\nâ””â”€â”€ Weave (Universe)\n    â”œâ”€â”€ Loom (Folder)\n    â”‚   â”œâ”€â”€ Strand (markdown file)\n    â”‚   â”œâ”€â”€ Strand (markdown file)\n    â”‚   â””â”€â”€ ...\n    â””â”€â”€ Loom (Folder)\n        â””â”€â”€ ...\n```\n\n**Fabric**: The entire Codex corpus viewed as one living whole\n- Composed of multiple weaves (e.g., `frame`, `wiki`, `technology`)\n- Enables cross-weave traversal when operating at Fabric scope\n- Used by superintelligence/agents for holistic aggregation and synthesis\n\n**Weave**: Complete, isolated knowledge universe\n- No cross-weave relationships\n- Independent scope and taxonomy\n- Examples: `wiki`, `frame`, `technology`\n\n**Loom**: Any folder inside a weave\n- Organized by topic or module\n- No explicit `looms/` prefix needed\n- Metadata in optional `loom.yaml`\n\n**Strand**: Any markdown file inside a weave\n- Self-contained, focused on one concept\n- Rich metadata in YAML frontmatter\n- No explicit `strands/` folder needed\n\n### Why This Structure?\n\n1. **Modularity**: Each strand is independent and reusable\n2. **Discoverability**: Looms (folders) provide natural organization\n3. **Isolation**: Weaves prevent namespace collisions\n4. **Scalability**: Can grow to millions of strands\n5. **AI-Friendly**: Clear structure for LLM ingestion\n6. **Simple**: Folders = looms, markdown files = strands (auto-detected)\n\n### Superintelligence at Fabric Scope\n\nWhile weaves remain isolated for organization and provenance, analysis at the **Fabric** level permits traversal across weaves for:\n\n- Cross-domain retrieval and context assembly\n- Whole-of-corpus synthesis and summarization\n- Global topic maps and knowledge graphs\n\nFabric-level queries always preserve original weave/loom/strand provenance.\n\n## SQL Cache Layer\n\nFrame Codex uses [@framers/sql-storage-adapter](https://github.com/framersai/sql-storage-adapter) for intelligent caching.\n\n### Performance\n\n- **First run**: ~30s for 100 files (full analysis)\n- **Subsequent**: ~2-5s for 5 changed files (85-95% speedup)\n- **Storage**: ~500KB-2MB for 100 files\n\n### How It Works\n\n1. **SHA-based change detection**: Only re-process modified files\n2. **Loom-scoped caching**: Store aggregate stats per loom (folder)\n3. **Keyword caching**: Pre-computed TF-IDF scores\n4. **GitHub Actions cache**: Persistent across CI runs\n\n### Cache Tables\n\n```sql\nfiles       -- File metadata, SHA, analysis JSON\nkeywords    -- Extracted keywords with TF-IDF scores\nstats       -- Loom/weave aggregate statistics\n```\n\n## Static NLP Pipeline\n\n**No LLM calls, $0 cost, runs in CI:**\n\n1. **TF-IDF**: Keyword extraction and ranking\n2. **N-grams**: Common phrase detection\n3. **Vocabulary matching**: Auto-categorization\n4. **Readability scoring**: Flesch-Kincaid grade level\n5. **Sentiment heuristics**: Simple keyword patterns\n\n### Output\n\n- `codex-index.json`: Searchable index for frame.dev/codex\n- `codex-report.json`: Analytics and validation results\n\n## Automation Workflows\n\n### On Every PR\n\n1. **Schema validation**: Required fields, types, enums\n2. **Content quality**: Length, forbidden patterns, duplicates\n3. **Static NLP**: Auto-categorization and tagging\n4. **Optional AI**: GPT-4 quality analysis (if `OPENAI_API_KEY` set)\n\n### Auto-Merge (Trusted Weavers)\n\n- Users in `.github/WEAVERS.txt` get auto-approved + merged\n- Requires 5+ high-quality contributions\n- Validation must pass\n\n### Full Re-Catalog\n\n- Triggered manually or on schedule\n- Updates all metadata and statistics\n- Creates PR (manual approval by default)\n- Toggle: `AUTO_CATALOG_MERGE=true`\n\n## OpenStrand Integration\n\nFrame Codex implements the **Educational Content Atom (ECA)** specification:\n\n- **Learning Design**: Objectives, outcomes, Bloom's taxonomy\n- **Time Estimates**: Reading, exercises, projects\n- **Modalities**: Text, visual, audio, video, kinesthetic\n- **Assessments**: Formative and summative\n- **Accessibility**: WCAG compliance, reading levels\n- **Quality Metrics**: Peer review, evidence-based claims\n\n### Frame Codex vs OpenStrand\n\n- **Frame Codex**: Public markdown repository (this repo)\n- **OpenStrand**: Full PKMS at openstrand.ai (all file types, AI analysis, private workspaces)\n\n## Repository Structure\n\n```\ncodex/\nâ”œâ”€â”€ weaves/              # Knowledge universes\nâ”‚   â”œâ”€â”€ wiki/           # Meta-documentation\nâ”‚   â”‚   â”œâ”€â”€ weave.yaml\nâ”‚   â”‚   â”œâ”€â”€ architecture/    # Loom (folder)\nâ”‚   â”‚   â”‚   â””â”€â”€ overview.md  # Strand (markdown file)\nâ”‚   â”‚   â””â”€â”€ ...\nâ”‚   â”œâ”€â”€ frame/          # Frame ecosystem knowledge\nâ”‚   â”‚   â”œâ”€â”€ weave.yaml\nâ”‚   â”‚   â”œâ”€â”€ openstrand/      # Loom (folder)\nâ”‚   â”‚   â”‚   â””â”€â”€ architecture.md  # Strand (markdown file)\nâ”‚   â”‚   â””â”€â”€ ...\nâ”‚   â””â”€â”€ technology/     # Tech & CS content\nâ”œâ”€â”€ schema/             # Validation schemas\nâ”œâ”€â”€ docs/               # Development guides\nâ”œâ”€â”€ scripts/            # Automation scripts\nâ”œâ”€â”€ tes",
    "searchText": "frame codex architecture overview high-level architecture of frame codex: three-tier knowledge organization, sql caching, static nlp, and automation codex fabric files auto sql analysis frame organization caching automation metadata structure validation quality loom frame codex loom folder strand markdown markdown file static nlp codex architecture architecture overview tier knowledge knowledge organization cross weave"
  },
  {
    "path": "weaves/wiki/architecture/qa-system.md",
    "name": "qa-system.md",
    "type": "file",
    "metadata": {
      "title": "Qa System",
      "summary": "Q&A System Architecture\n\nThe Frame Codex Q&A system represents a paradigm shift in knowledge retrievalâ€”combining the precision of semantic search with the intuition of natural language understanding",
      "autoGenerated": {
        "keywords": [
          "string",
          "authentication",
          "interface",
          "answer",
          "language",
          "questions",
          "embedding",
          "api",
          "onnx",
          "code",
          "security",
          "codex",
          "search",
          "typescript",
          "model"
        ],
        "phrases": [
          "frame codex",
          "semantic search",
          "natural language",
          "multi source",
          "onnx runtime",
          "typescript interface",
          "architecture frame",
          "codex represents",
          "represents paradigm",
          "paradigm shift"
        ],
        "subjects": [],
        "topics": [],
        "difficulty": "intermediate",
        "confidence": {},
        "readingLevel": 0,
        "readabilityScore": 0,
        "statistics": {},
        "entities": {
          "people": [
            "PAT             â”‚"
          ],
          "places": [
            "Architecture](/codex/security/overview)"
          ],
          "organizations": [
            "[GitHub",
            "Resource Management",
            "Privacy & Security",
            "API Design",
            "UX design,"
          ],
          "topics": [
            "UX design,",
            "API Design",
            "Privacy & Security",
            "Resource Management",
            "[GitHub",
            "Architecture](/codex/security/overview)",
            "PAT             â”‚"
          ]
        },
        "lastIndexed": "2025-12-01T07:58:06.592Z"
      }
    },
    "validation": {
      "valid": true,
      "errors": [],
      "warnings": [],
      "suggestions": [
        "Add unique ID (UUID recommended)",
        "Add version number (semver format)",
        "Consider adding tags: string, authentication, interface, answer, language",
        "Consider adding relationships (requires, references, seeAlso)",
        "Auto-detected subjects: ",
        "Auto-detected topics: ",
        "Suggested difficulty: intermediate",
        "Key phrases found: frame codex, semantic search, natural language"
      ]
    },
    "content": "# Q&A System Architecture\n\nThe Frame Codex Q&A system represents a paradigm shift in knowledge retrievalâ€”combining the precision of semantic search with the intuition of natural language understanding. This document outlines the architecture, implementation, and philosophy behind our question-answering oracle.\n\n## Philosophy: Questions as Knowledge Traversal\n\nTraditional search treats queries as keyword matching exercises. The Frame Codex Q&A system treats **questions as journeys through the knowledge graph**. When you ask \"How does authentication work?\", you're not looking for documents containing \"authentication\"â€”you're seeking understanding of a concept's mechanics, relationships, and implications.\n\n## Core Architecture\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                         User Interface                        â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚\nâ”‚  â”‚   Question   â”‚  â”‚   Suggested  â”‚  â”‚  Answer Cards   â”‚  â”‚\nâ”‚  â”‚    Input     â”‚  â”‚  Questions   â”‚  â”‚  (Contextual)   â”‚  â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n          â”‚                                         â”‚\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                    Question Processor              â”‚          â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚\nâ”‚  â”‚   Intent     â”‚  â”‚   Entity     â”‚  â”‚  Answer Builder   â”‚ â”‚\nâ”‚  â”‚  Analyzer    â”‚  â”‚  Extractor   â”‚  â”‚  (Multi-source)   â”‚ â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n          â”‚                 â”‚                   â”‚\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                  Semantic Search Engine         â”‚          â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚\nâ”‚  â”‚   ONNX       â”‚  â”‚  Embedding   â”‚  â”‚  Similarity    â”‚ â”‚\nâ”‚  â”‚  Runtime     â”‚  â”‚   Index      â”‚  â”‚   Scoring      â”‚ â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n## Components\n\n### 1. Question Input Interface\n\nThe entry point for natural language queries with intelligent features:\n\n- **Auto-complete** based on common questions and recent queries\n- **Voice input** with real-time transcription\n- **Question templates** for common patterns\n- **Multi-language** support with automatic translation\n\n### 2. Question Processor\n\nTransforms natural language into structured queries:\n\n#### Intent Analyzer\n- Classifies question types: How, What, Where, Why, When\n- Identifies action verbs: implement, configure, debug, optimize\n- Detects scope: specific file, concept, or system-wide\n\n#### Entity Extractor\n- Identifies key concepts: authentication, React hooks, API endpoints\n- Extracts constraints: \"in TypeScript\", \"for production\", \"with examples\"\n- Recognizes relationships: \"difference between X and Y\"\n\n### 3. Semantic Search Engine\n\nThe heart of intelligent retrieval:\n\n#### ONNX Runtime Web\n- Runs MiniLM-L6-v2 model entirely in the browser\n- No server calls = complete privacy\n- ~22MB model size with 384-dimensional embeddings\n- Sub-100ms inference time\n\n#### Embedding Index\n- Pre-computed embeddings for all strands\n- Stored in `codex-embeddings.json`\n- Hierarchical indexing: strand â†’ section â†’ paragraph\n- Incremental updates on new content\n\n#### Similarity Scoring\n- Cosine similarity for semantic matching\n- BM25 for keyword relevance\n- Hybrid scoring: 0.7 Ã— semantic + 0.3 Ã— keyword\n- Context window expansion for better answers\n\n### 4. Answer Builder\n\nConstructs comprehensive, contextual responses:\n\n- **Multi-source synthesis**: Combines relevant sections from multiple strands\n- **Code extraction**: Highlights relevant code snippets\n- **Visual aids**: Includes diagrams and images when helpful\n- **Related links**: Suggests deeper reading\n- **Confidence scoring**: Shows relevance percentage\n\n## Data Flow\n\n```\n1. User asks: \"How do I implement authentication with JWT?\"\n   â†“\n2. Intent: HOW_TO + IMPLEMENT\n   Entities: [\"authentication\", \"JWT\"]\n   Constraints: [\"implementation\"]\n   â†“\n3. Query embedding: [0.23, -0.45, 0.67, ...] (384 dims)\n   â†“\n4. Search index for nearest neighbors\n   - auth-jwt-guide.md (0.92 similarity)\n   - security-best-practices.md (0.87 similarity)\n   - api-design.md (0.76 similarity)\n   â†“\n5. Extract relevant sections + expand context\n   â†“\n6. Build answer with:\n   - Summary paragraph\n   - Step-by-step implementation\n   - Code examples\n   - Security considerations\n   - Links to full strands\n```\n\n## Embedding Generation\n\n### Pre-processing Pipeline\n\n```typescript\ninterface EmbeddingEntry {\n  id: string              // Unique identifier\n  path: string           // Strand path\n  content: string        // Text content\n  embedding: number[]    // 384-dimensional vector\n  metadata: {\n    type: 'strand' | 'section' | 'code'\n    title: string\n    tags: string[]",
    "searchText": "qa system q&a system architecture\n\nthe frame codex q&a system represents a paradigm shift in knowledge retrievalâ€”combining the precision of semantic search with the intuition of natural language understanding string authentication interface answer language questions embedding api onnx code security codex search typescript model frame codex semantic search natural language multi source onnx runtime typescript interface architecture frame codex represents represents paradigm paradigm shift"
  },
  {
    "path": "weaves/wiki/examples/gallery-demo.md",
    "name": "gallery-demo.md",
    "type": "file",
    "metadata": {
      "title": "Gallery Demo",
      "summary": "Individual Images\n\nSingle images display normally:\n\n![A beautiful sunset](https://images.unsplash.com/photo-1506905925346-21bda4d32df4?w=800)\n\nAutomatic Gallery Wall\n\nWhen you have 3 or more images in sequence, they transform into a stunning Art Deco gallery:\n\n![Mountain landscape](https://images...",
      "autoGenerated": {
        "keywords": [
          "unsplash",
          "photo",
          "images",
          "gallery",
          "https",
          "600",
          "com",
          "image",
          "400",
          "1506905925346",
          "21bda4d32df4",
          "deco",
          "demo",
          "sunset",
          "golden"
        ],
        "phrases": [
          "https images",
          "images unsplash",
          "unsplash com",
          "com photo",
          "photo 1506905925346",
          "1506905925346 21bda4d32df4",
          "image https",
          "gallery demo",
          "sunset https",
          "automatic gallery"
        ],
        "subjects": [],
        "topics": [],
        "difficulty": "intermediate",
        "confidence": {},
        "readingLevel": 0,
        "readabilityScore": 0,
        "statistics": {},
        "entities": {
          "people": [
            "- **Art Deco Frames**:"
          ],
          "places": [
            "Art Deco gallery:",
            "Golden Gate Bridge",
            "![New York City",
            "![Paris",
            "![Tokyo",
            "Gallery Demo"
          ],
          "organizations": [],
          "topics": [
            "Gallery Demo",
            "![Tokyo",
            "![Paris",
            "![New York City",
            "Golden Gate Bridge",
            "Art Deco gallery:",
            "- **Art Deco Frames**:"
          ]
        },
        "lastIndexed": "2025-12-01T07:58:06.676Z"
      }
    },
    "validation": {
      "valid": true,
      "errors": [],
      "warnings": [],
      "suggestions": [
        "Add unique ID (UUID recommended)",
        "Add version number (semver format)",
        "Consider adding tags: unsplash, photo, images, gallery, https",
        "Consider adding relationships (requires, references, seeAlso)",
        "Auto-detected subjects: ",
        "Auto-detected topics: ",
        "Suggested difficulty: intermediate",
        "Key phrases found: https images, images unsplash, unsplash com"
      ]
    },
    "content": "# Art Deco Gallery Demo\n\nThis strand demonstrates the automatic gallery generation for multiple images.\n\n## Individual Images\n\nSingle images display normally:\n\n![A beautiful sunset](https://images.unsplash.com/photo-1506905925346-21bda4d32df4?w=800)\n\n## Automatic Gallery Wall\n\nWhen you have 3 or more images in sequence, they transform into a stunning Art Deco gallery:\n\n![Mountain landscape](https://images.unsplash.com/photo-1506905925346-21bda4d32df4?w=600)\n![Ocean waves](https://images.unsplash.com/photo-1505142468610-359e7d316be0?w=600)\n![Forest path](https://images.unsplash.com/photo-1441974231531-c6227db76b6e?w=600)\n![Desert dunes](https://images.unsplash.com/photo-1509316785289-025f5b846b35?w=600)\n![City lights](https://images.unsplash.com/photo-1514565131-fce0801e5785?w=600)\n\n## Gallery with Captions\n\nThe gallery preserves your image alt text as captions:\n\n![The Golden Gate Bridge at sunset](https://images.unsplash.com/photo-1449034446853-66c86144b0ad?w=600)\n![New York City skyline](https://images.unsplash.com/photo-1518391846015-55a9cc003b25?w=600)\n![Paris Eiffel Tower](https://images.unsplash.com/photo-1502602898657-3e91760cbb34?w=600)\n![Tokyo at night](https://images.unsplash.com/photo-1536098561742-ca998e48cbcc?w=600)\n\n## Mixed Content\n\nRegular text breaks the gallery grouping:\n\n![First image](https://images.unsplash.com/photo-1506905925346-21bda4d32df4?w=400)\n![Second image](https://images.unsplash.com/photo-1505142468610-359e7d316be0?w=400)\n\nSome text in between...\n\n![Third image](https://images.unsplash.com/photo-1441974231531-c6227db76b6e?w=400)\n![Fourth image](https://images.unsplash.com/photo-1509316785289-025f5b846b35?w=400)\n\n## Features\n\n- **Golden Ratio Layout**: Images are sized using Ï† (1.618)\n- **Art Deco Frames**: Each image gets an ornate golden frame\n- **Hover Effects**: Images scale up on hover\n- **Responsive**: Adapts to mobile screens\n- **Theme Aware**: Works with light, dark, and sepia themes\n- **Lightbox Ready**: Click to view full size (coming soon)\n\n---\n\nmetadata:\ntitle: Gallery Demo\ntags: [examples, media, gallery]\ncreated: 2024-01-01\n",
    "searchText": "gallery demo individual images\n\nsingle images display normally:\n\n![a beautiful sunset](https://images.unsplash.com/photo-1506905925346-21bda4d32df4?w=800)\n\nautomatic gallery wall\n\nwhen you have 3 or more images in sequence, they transform into a stunning art deco gallery:\n\n![mountain landscape](https://images... unsplash photo images gallery https 600 com image 400 1506905925346 21bda4d32df4 deco demo sunset golden https images images unsplash unsplash com com photo photo 1506905925346 1506905925346 21bda4d32df4 image https gallery demo sunset https automatic gallery"
  },
  {
    "path": "weaves/wiki/tutorials/getting-started.md",
    "name": "getting-started.md",
    "type": "file",
    "metadata": {
      "title": "Getting Started",
      "summary": "Getting Started with Frame Codex\n\nWelcome to the **Frame Codex** â€” a revolutionary knowledge system that combines the elegance of Art Deco with the power of modern AI",
      "autoGenerated": {
        "keywords": [
          "jpg",
          "tutorials",
          "codex",
          "started",
          "open",
          "wiki",
          "photo",
          "sidebar",
          "drawings",
          "photos",
          "media",
          "markdown",
          "deco",
          "code",
          "audio"
        ],
        "phrases": [
          "frame codex",
          "wiki tutorials",
          "started frame",
          "code blocks",
          "save draft",
          "markdown features",
          "jpg photo",
          "codex welcome",
          "welcome frame",
          "codex revolutionary"
        ],
        "subjects": [],
        "topics": [],
        "difficulty": "intermediate",
        "confidence": {},
        "readingLevel": 0,
        "readabilityScore": 0,
        "statistics": {},
        "entities": {
          "people": [
            "Art Deco",
            "Art Deco"
          ],
          "places": [
            "**Library of Alexandria**,",
            "strand](/wiki/architecture/overview)",
            "\"New York City\","
          ],
          "organizations": [
            "GitHub!",
            "**GitHub",
            "- [Search & Discovery](/wiki/tutorials/search-guide) â€”"
          ],
          "topics": [
            "- [Search & Discovery](/wiki/tutorials/search-guide) â€”",
            "**GitHub",
            "GitHub!",
            "\"New York City\",",
            "strand](/wiki/architecture/overview)",
            "**Library of Alexandria**,",
            "Art Deco",
            "Art Deco"
          ]
        },
        "lastIndexed": "2025-12-01T07:58:06.978Z"
      }
    },
    "validation": {
      "valid": true,
      "errors": [],
      "warnings": [],
      "suggestions": [
        "Add unique ID (UUID recommended)",
        "Add version number (semver format)",
        "Consider adding tags: jpg, tutorials, codex, started, open",
        "Consider adding relationships (requires, references, seeAlso)",
        "Auto-detected subjects: ",
        "Auto-detected topics: ",
        "Suggested difficulty: intermediate",
        "Key phrases found: frame codex, wiki tutorials, started frame"
      ]
    },
    "content": "# Getting Started with Frame Codex\n\nWelcome to the **Frame Codex** â€” a revolutionary knowledge system that combines the elegance of Art Deco with the power of modern AI. This tutorial will guide you through the basics of navigating, reading, and contributing to the Codex.\n\n## What is Frame Codex?\n\nFrame Codex is a **four-tier hierarchical knowledge base** designed for both humans and AI to explore, learn, and grow together. Think of it as the **Hitchhiker's Guide to the Galaxy** meets the **Library of Alexandria**, wrapped in golden Art Deco splendor.\n\n### The Four-Tier Architecture\n\n1. **Fabric** â€” The entire knowledge universe (the whole Codex)\n2. **Weave** â€” A thematic collection (e.g., \"Wiki\", \"Tutorials\", \"Research\")\n3. **Loom** â€” A category within a weave (e.g., \"Architecture\", \"Examples\")\n4. **Strand** â€” An individual document (like this one!)\n\n```\nFabric (Frame Codex)\nâ””â”€â”€ Weave (wiki)\n    â””â”€â”€ Loom (tutorials)\n        â””â”€â”€ Strand (getting-started.md)\n```\n\n## Navigation Basics\n\n### The Sidebar\n\nThe left sidebar shows your current location in the hierarchy:\n\n- **Weaves** are shown in bold with distinctive colors\n- **Looms** are nested underneath weaves\n- **Strands** appear as clickable items within looms\n- Current selection is highlighted with a golden ring\n\n### The Content Area\n\nThe center panel displays your selected strand in beautiful markdown rendering with:\n\n- Syntax highlighting for code blocks\n- Auto-generated galleries for multiple images\n- Embedded media support (audio, video, drawings)\n- Interactive elements\n\n### The Metadata Panel\n\nThe right sidebar shows:\n\n- **File info** â€” path, size, last modified\n- **Tags** â€” auto-suggested or manual keywords\n- **Readability** â€” Flesch-Kincaid score and estimated reading time\n- **Vocabulary** â€” domain-specific terms found in the strand\n- **Sentiment** â€” emotional tone analysis\n\n## Your First Strand\n\nLet's create your first knowledge strand!\n\n### 1. Open the Editor\n\nPress the **Edit** button in the toolbar (or press `E` on your keyboard).\n\n### 2. Write Your Content\n\nUse the split-pane editor to write in Markdown:\n\n```markdown\n# My First Strand\n\nThis is a paragraph of text.\n\n## A Subheading\n\n- Bullet point 1\n- Bullet point 2\n\n**Bold text** and *italic text* work too!\n```\n\n### 3. Add Media\n\nClick the **sparkle icon** âœ¨ to open the radial media menu:\n\n- ğŸ“· **Camera** â€” Take a photo or upload an image\n- ğŸ™ï¸ **Voice** â€” Record audio notes\n- ğŸ¨ **Draw** â€” Open the infinite whiteboard canvas\n- ğŸ’» **Code** â€” Insert syntax-highlighted code blocks\n\n### 4. Save Your Draft\n\nClick **Save Draft** to store locally (auto-saves every 5 seconds).\n\n### 5. Publish Your Changes\n\nClick **Publish** to create a pull request on GitHub!\n\nThe system will:\n1. Fork the repository (if needed)\n2. Upload your media assets\n3. Create a branch\n4. Commit your changes\n5. Open a PR for review\n\n## Markdown Features\n\nFrame Codex supports **GitHub Flavored Markdown** with special enhancements:\n\n### Basic Formatting\n\n```markdown\n**Bold** \n*Italic* \n`Inline code` \n~~Strikethrough~~\n```\n\n### Links and References\n\n```markdown\n[External link](https://example.com)\n[Internal strand](/wiki/architecture/overview)\n```\n\n### Images\n\n```markdown\n![Single image](./photo.jpg)\n```\n\nWhen you add 3+ images in a row, they automatically become a gallery!\n\n```markdown\n![Photo 1](./img1.jpg)\n![Photo 2](./img2.jpg)\n![Photo 3](./img3.jpg)\n![Photo 4](./img4.jpg)\n```\n\n### Code Blocks\n\n````markdown\n```javascript\nfunction fibonacci(n) {\n  if (n <= 1) return n\n  return fibonacci(n - 1) + fibonacci(n - 2)\n}\n```\n````\n\n### Tables\n\n```markdown\n| Feature | Status |\n|---------|--------|\n| Gallery | âœ… |\n| Voice | âœ… |\n| Whiteboard | âœ… |\n```\n\n### Math (Coming Soon)\n\n```markdown\nInline: $E = mc^2$\n\nBlock:\n$$\n\\phi = \\frac{1 + \\sqrt{5}}{2} \\approx 1.618\n$$\n```\n\n## Media as Strands\n\nIn Frame Codex, **everything is a strand** â€” including media files!\n\n### Photos\n\nWhen you capture a photo, it becomes a strand in `./assets/photos/` and is automatically:\n- Timestamped\n- Linked to the parent strand\n- Indexed for search\n- Added to the gallery if there are multiple\n\n### Audio\n\nVoice recordings are saved as `./assets/audio/*.webm` and can be:\n- Played inline\n- Transcribed (coming soon)\n- Tagged with keywords\n- Searched by content\n\n### Drawings\n\nWhiteboard sketches export as SVG to `./assets/drawings/` and retain:\n- Full vector quality\n- Infinite canvas context\n- Golden ratio guides\n- Layer information\n\n## The Recursive Nature of Strands\n\nHere's where it gets magical: **strands can contain strands**.\n\nA single media collection can be treated as one logical strand with a `catalog.json` schema:\n\n```json\n{\n  \"type\": \"gallery\",\n  \"title\": \"Art Deco Architecture Photos\",\n  \"strands\": [\n    \"./chrysler-building.jpg\",\n    \"./empire-state.jpg\",\n    \"./rockefeller-center.jpg\"\n  ],\n  \"metadata\": {\n    \"location\": \"New York City\",\n    \"period\": \"1920-1940\",\n    \"style\": \"Art Deco\"\n  }\n}\n```\n\nThis catalog **itself becomes a traversable node** in the knowled",
    "searchText": "getting started getting started with frame codex\n\nwelcome to the **frame codex** â€” a revolutionary knowledge system that combines the elegance of art deco with the power of modern ai jpg tutorials codex started open wiki photo sidebar drawings photos media markdown deco code audio frame codex wiki tutorials started frame code blocks save draft markdown features jpg photo codex welcome welcome frame codex revolutionary"
  },
  {
    "path": "weaves/wiki/tutorials/markdown-features.md",
    "name": "markdown-features.md",
    "type": "file",
    "metadata": {
      "title": "Markdown Features",
      "summary": "Markdown Features Guide\n\nFrame Codex supports **GitHub Flavored Markdown (GFM)** plus custom enhancements for knowledge management",
      "autoGenerated": {
        "keywords": [
          "item",
          "heading",
          "markdown",
          "html",
          "task",
          "lists",
          "aligned",
          "nested",
          "jpg",
          "don",
          "another",
          "openai",
          "fibonacci",
          "add",
          "details"
        ],
        "phrases": [
          "frame codex",
          "item item",
          "item nested",
          "nested item",
          "heading heading",
          "markdown features",
          "codex supports",
          "text text",
          "features guide",
          "inline code"
        ],
        "subjects": [],
        "topics": [],
        "difficulty": "intermediate",
        "confidence": {},
        "readingLevel": 0,
        "readabilityScore": 0,
        "statistics": {},
        "entities": {
          "people": [
            "- Art Deco",
            "Alan Kay",
            "Francis Bacon",
            "Alan Kay",
            "- Skip",
            "\"Art Deco"
          ],
          "places": [
            "\"Example Site\")",
            "Art Deco gallery**:",
            "\"New York\""
          ],
          "organizations": [
            "**GitHub",
            "return n  //"
          ],
          "topics": [
            "return n  //",
            "**GitHub",
            "\"New York\"",
            "Art Deco gallery**:",
            "\"Example Site\")",
            "\"Art Deco",
            "- Skip",
            "Alan Kay",
            "Francis Bacon",
            "Alan Kay",
            "- Art Deco"
          ]
        },
        "lastIndexed": "2025-12-01T07:58:07.387Z"
      }
    },
    "validation": {
      "valid": true,
      "errors": [],
      "warnings": [],
      "suggestions": [
        "Add unique ID (UUID recommended)",
        "Add version number (semver format)",
        "Consider adding tags: item, heading, markdown, html, task",
        "Consider adding relationships (requires, references, seeAlso)",
        "Auto-detected subjects: ",
        "Auto-detected topics: ",
        "Suggested difficulty: intermediate",
        "Key phrases found: frame codex, item item, item nested"
      ]
    },
    "content": "# Markdown Features Guide\n\nFrame Codex supports **GitHub Flavored Markdown (GFM)** plus custom enhancements for knowledge management. This guide covers every feature available to you.\n\n## Philosophy\n\n> \"Markdown is a lightweight markup language with plain-text formatting syntax designed so that it can be converted to HTML and many other formats.\"\n\nIn Frame Codex, markdown serves as the **universal language** for human-readable knowledge that machines can also parse, index, and synthesize.\n\n## Text Formatting\n\n### Basic Emphasis\n\n```markdown\n*italic* or _italic_\n**bold** or __bold__\n***bold italic*** or ___bold italic___\n~~strikethrough~~\n`inline code`\n```\n\n**Renders as:**\n\n*italic* or _italic_  \n**bold** or __bold__  \n***bold italic*** or ___bold italic___  \n~~strikethrough~~  \n`inline code`\n\n### Subscript and Superscript\n\n```markdown\nH~2~O  \nE = mc^2^\n```\n\nH~2~O  \nE = mc^2^\n\n## Headings\n\n```markdown\n# Heading 1\n## Heading 2\n### Heading 3\n#### Heading 4\n##### Heading 5\n###### Heading 6\n```\n\n**Best practices:**\n- Use one `#` heading per strand (the title)\n- Start hierarchy at `##` for sections\n- Don't skip levels (e.g., `##` â†’ `####`)\n- Keep headings concise and descriptive\n\n## Lists\n\n### Unordered Lists\n\n```markdown\n- Item 1\n- Item 2\n  - Nested item 2.1\n  - Nested item 2.2\n- Item 3\n\n* Also works\n+ This too\n```\n\n- Item 1\n- Item 2\n  - Nested item 2.1\n  - Nested item 2.2\n- Item 3\n\n### Ordered Lists\n\n```markdown\n1. First item\n2. Second item\n   1. Nested ordered\n   2. Another nested\n3. Third item\n```\n\n1. First item\n2. Second item\n   1. Nested ordered\n   2. Another nested\n3. Third item\n\n### Task Lists\n\n```markdown\n- [x] Completed task\n- [ ] Uncompleted task\n- [ ] Another task\n```\n\n- [x] Completed task\n- [ ] Uncompleted task\n- [ ] Another task\n\n## Links\n\n### External Links\n\n```markdown\n[OpenAI](https://openai.com)\n[Link with title](https://example.com \"Example Site\")\n```\n\n[OpenAI](https://openai.com)\n\n### Internal Strand Links\n\n```markdown\n[Architecture Overview](/wiki/architecture/overview)\n[Getting Started](./getting-started)\n```\n\n### Autolinks\n\n```markdown\nhttps://frame.dev automatically becomes a link\n```\n\nhttps://frame.dev\n\n### Reference Links\n\n```markdown\nI love [Frame Codex][1] and [OpenStrand][2].\n\n[1]: https://frame.dev\n[2]: https://github.com/openstrand\n```\n\n## Images\n\n### Single Image\n\n```markdown\n![Alt text](./image.jpg)\n![With title](./image.jpg \"Image Title\")\n```\n\n### Automatic Gallery (3+ Images)\n\nWhen you add 3 or more images consecutively, Frame Codex automatically creates a **golden-framed Art Deco gallery**:\n\n```markdown\n![Photo 1](./img1.jpg)\n![Photo 2](./img2.jpg)\n![Photo 3](./img3.jpg)\n![Photo 4](./img4.jpg)\n```\n\nFeatures:\n- Golden ratio layout (Ï† â‰ˆ 1.618)\n- Art Deco corner ornaments\n- Hover effects\n- Responsive grid\n- Theme-aware styling\n\n### Image Sizing (HTML)\n\n```markdown\n<img src=\"./logo.png\" width=\"300\" alt=\"Logo\">\n```\n\n## Code\n\n### Inline Code\n\n```markdown\nUse `const` instead of `var` in JavaScript.\n```\n\nUse `const` instead of `var` in JavaScript.\n\n### Code Blocks\n\n````markdown\n```javascript\nfunction fibonacci(n) {\n  if (n <= 1) return n\n  return fibonacci(n - 1) + fibonacci(n - 2)\n}\n```\n````\n\nSupported languages include:\n- `javascript` / `typescript` / `jsx` / `tsx`\n- `python` / `rust` / `go` / `c` / `cpp` / `java`\n- `bash` / `shell` / `powershell`\n- `json` / `yaml` / `toml` / `xml`\n- `markdown` / `html` / `css` / `scss`\n- `sql` / `graphql`\n- And many more!\n\n### Code with Line Numbers\n\n````markdown\n```typescript {1,3-5}\nconst phi = (1 + Math.sqrt(5)) / 2  // highlighted\nconst fibonacci = (n: number): number => {\n  if (n <= 1) return n  // highlighted\n  return fibonacci(n - 1) + fibonacci(n - 2)  // highlighted\n}\n```\n````\n\n## Tables\n\n```markdown\n| Feature | Status | Priority |\n|---------|--------|----------|\n| Gallery | âœ… Done | High |\n| Voice Recorder | âœ… Done | Medium |\n| Q&A System | ğŸš§ In Progress | High |\n| API | ğŸ“‹ Planned | Low |\n```\n\n**Alignment:**\n\n```markdown\n| Left-aligned | Center-aligned | Right-aligned |\n|:------------|:--------------:|--------------:|\n| Text        | Text           | Text          |\n```\n\n| Left-aligned | Center-aligned | Right-aligned |\n|:------------|:--------------:|--------------:|\n| Text        | Text           | Text          |\n\n## Blockquotes\n\n```markdown\n> \"The best way to predict the future is to invent it.\"\n> â€” Alan Kay\n\n> Nested quotes:\n>> \"Knowledge is power.\"\n>> â€” Francis Bacon\n```\n\n> \"The best way to predict the future is to invent it.\"  \n> â€” Alan Kay\n\n## Horizontal Rules\n\n```markdown\n---\n***\n___\n```\n\nAll three render as:\n\n---\n\n## HTML Support\n\nFrame Codex supports raw HTML for advanced layouts:\n\n```html\n<div style=\"text-align: center; padding: 2rem; background: linear-gradient(135deg, #FFD700, #B8860B); border-radius: 0.5rem;\">\n  <h3>Art Deco Box</h3>\n  <p>Custom styled content</p>\n</div>\n```\n\n### Details/Summary (Collapsible)\n\n```markdown\n<details>\n<summary>Click to expand</summary>\n\nHidden content goes here!\n\n- Can contain markdown\n- And ",
    "searchText": "markdown features markdown features guide\n\nframe codex supports **github flavored markdown (gfm)** plus custom enhancements for knowledge management item heading markdown html task lists aligned nested jpg don another openai fibonacci add details frame codex item item item nested nested item heading heading markdown features codex supports text text features guide inline code"
  },
  {
    "path": "weaves/wiki/tutorials/media-guide.md",
    "name": "media-guide.md",
    "type": "file",
    "metadata": {
      "title": "Media Guide",
      "summary": "Media Guide: Photos, Audio, Drawings & More\n\nFrame Codex treats **all media as first-class knowledge strands**",
      "autoGenerated": {
        "keywords": [
          "photos",
          "assets",
          "audio",
          "drawings",
          "jpg",
          "timestamp",
          "drawing",
          "svg",
          "upload",
          "radial",
          "menu",
          "click",
          "zoom",
          "media",
          "voice"
        ],
        "phrases": [
          "assets photos",
          "radial menu",
          "media guide",
          "audio drawings",
          "golden gate",
          "guide photos",
          "photos audio",
          "frame codex",
          "saved assets",
          "alt text"
        ],
        "subjects": [],
        "topics": [],
        "difficulty": "intermediate",
        "confidence": {},
        "readingLevel": 0,
        "readabilityScore": 0,
        "statistics": {},
        "entities": {
          "people": [
            "**Art Deco",
            "**Art Deco",
            "\"Art Deco",
            "- Skip"
          ],
          "places": [
            "Gallery Wall",
            "**Art Deco gallery**:",
            "![Bay Bridge](./assets/photos/bay-bridge.jpg)",
            "Golden Gate Bridge",
            "San Francisco,",
            "\"San Francisco",
            "\"San Francisco,",
            "- [Gallery Demo](/wiki/examples/gallery-demo)"
          ],
          "organizations": [
            "Drawings & More",
            "VU",
            "Knowledge Management:**",
            "Drawings & Whiteboard",
            "Music & Podcasts",
            "EXIF Data",
            "- Stroke data",
            "Publishing Media",
            "**Draft Saved** â€” Media",
            "GitHub"
          ],
          "topics": [
            "GitHub",
            "Media",
            "**Draft Saved** â€”",
            "Publishing Media",
            "- Stroke data",
            "EXIF Data",
            "Music & Podcasts",
            "Drawings & Whiteboard",
            "Knowledge Management:**",
            "VU",
            "Drawings & More",
            "- [Gallery Demo](/wiki/examples/gallery-demo)",
            "\"San Francisco,",
            "\"San Francisco",
            "San Francisco,"
          ]
        },
        "lastIndexed": "2025-12-01T07:58:07.942Z"
      }
    },
    "validation": {
      "valid": true,
      "errors": [],
      "warnings": [],
      "suggestions": [
        "Add unique ID (UUID recommended)",
        "Add version number (semver format)",
        "Consider adding tags: photos, assets, audio, drawings, jpg",
        "Consider adding relationships (requires, references, seeAlso)",
        "Auto-detected subjects: ",
        "Auto-detected topics: ",
        "Suggested difficulty: intermediate",
        "Key phrases found: assets photos, radial menu, media guide"
      ]
    },
    "content": "# Media Guide: Photos, Audio, Drawings & More\n\nFrame Codex treats **all media as first-class knowledge strands**. This guide shows you how to capture, upload, organize, and reference multimedia content in your Codex.\n\n## Philosophy: Everything is a Strand\n\nIn traditional knowledge bases, media files are mere \"attachments.\" In Frame Codex, they are **strands** â€” interconnected nodes in the knowledge graph.\n\nA photo isn't just decorationâ€”it's a semantic object with:\n- **Context** (when, where, why it was taken)\n- **Relationships** (linked to parent strand, related concepts)\n- **Metadata** (tags, sentiment, visual features)\n- **Discoverability** (searchable, indexed, recommended)\n\n## The Radial Media Menu\n\nTo insert media, press the **sparkle icon** âœ¨ in the editor. This opens the **Art Deco Radial Menu** with options arranged in a circle:\n\n### Available Options\n\n| Icon | Type | Description |\n|------|------|-------------|\n| ğŸ“· | **Camera** | Capture or upload photos |\n| ğŸ™ï¸ | **Voice** | Record audio notes |\n| ğŸ¨ | **Draw** | Open whiteboard canvas |\n| ğŸ’» | **Code** | Insert code blocks |\n| ğŸ–¼ï¸ | **Image** | Upload from file system |\n| ğŸ”— | **Link** | Insert external links |\n| #ï¸âƒ£ | **Tag** | Add semantic tags |\n| âœï¸ | **Heading** | Insert section heading |\n\n## ğŸ“· Photos\n\n### Capture with Camera\n\n1. Click **Camera** in the radial menu\n2. A Polaroid-style UI appears\n3. Click **Capture** to take a photo\n4. Apply retro filters:\n   - **Sepia** â€” Vintage warmth\n   - **Noir** â€” Black & white\n   - **Vintage** â€” Faded 1970s look\n5. Click **Use Photo** to insert\n\nThe photo is automatically:\n- Saved to `./assets/photos/photo-{timestamp}.jpg`\n- Linked in the markdown: `![Photo](./assets/photos/photo-xxx.jpg)`\n- Uploaded when you publish (via PR workflow)\n\n### Upload from File\n\n1. Click **Image** in the radial menu\n2. Select file from your device\n3. Image is copied to `./assets/photos/`\n4. Reference inserted in markdown\n\n### Gallery Wall\n\nWhen you add **3 or more photos** in sequence, they automatically transform into an **Art Deco gallery**:\n\n```markdown\n![Golden Gate](./assets/photos/golden-gate.jpg)\n![Bay Bridge](./assets/photos/bay-bridge.jpg)\n![Alcatraz](./assets/photos/alcatraz.jpg)\n```\n\n**Features:**\n- Golden ratio layout (Ï† â‰ˆ 1.618)\n- Ornate golden frames\n- Hover to zoom\n- Click for lightbox (coming soon)\n- Responsive grid\n\n### Best Practices\n\nâœ… **Do:**\n- Add descriptive alt text\n- Optimize images (< 2MB recommended)\n- Use consistent naming (lowercase, hyphens)\n- Group related photos together\n\nâŒ **Don't:**\n- Upload extremely large files (>10MB)\n- Use generic names like `image1.jpg`\n- Forget to publish your assets!\n\n## ğŸ™ï¸ Voice Recordings\n\n### Record Audio\n\n1. Click **Voice** in the radial menu\n2. A retro cassette tape UI appears\n3. Click **Record** to start\n4. Watch the VU meter visualize your voice\n5. Click **Pause** to pause (reels stop spinning)\n6. Click **Stop** to finish\n7. Review and **Use Recording**\n\nThe audio is automatically:\n- Saved as `./assets/audio/voice-{timestamp}.webm`\n- Inserted as `<audio controls src=\"./assets/audio/voice-xxx.webm\"></audio>`\n- Optimized for web playback\n\n### Audio Notes Use Cases\n\n**Personal Knowledge Management:**\n- Quick voice memos while reading\n- Reflections after completing a task\n- Verbal explanations of complex ideas\n\n**Collaboration:**\n- Leave voice comments on a strand\n- Narrate a tutorial or walkthrough\n- Record interviews or conversations\n\n**Learning:**\n- Practice pronunciation\n- Record lecture snippets\n- Audio flashcards\n\n### Transcription (Coming Soon)\n\nVoice recordings will be transcribed using Whisper.js (client-side) so you can:\n- Search audio content by words\n- Generate captions automatically\n- Convert speech to markdown\n\n## ğŸ¨ Drawings & Whiteboard\n\n### The Infinite Canvas\n\n1. Click **Draw** in the radial menu\n2. The **Art Deco Whiteboard** opens fullscreen\n3. Draw freely with pan & zoom\n4. Toggle **Grid** for precision\n5. Toggle **Golden Guides** for Ï†-ratio composition\n6. Click **Export** to save\n\n### Canvas Features\n\n- **Infinite pan** â€” Never run out of space\n- **Zoom** â€” Pinch or scroll to zoom in/out\n- **Drawing tools** â€” Pen, shapes, text, arrows\n- **Undo/Redo** â€” Never lose your work\n- **Dark mode** â€” Auto-adapts to your theme\n- **SVG export** â€” Perfect vector quality\n\n### Golden Ratio Guides\n\nEnable guides to see:\n- **Vertical lines** at 38.2% and 61.8%\n- **Horizontal lines** at 38.2% and 61.8%\n- **Concentric circles** for focal points\n\nThese are based on Ï† (phi) and help create visually balanced compositions.\n\n### Drawings as Strands\n\nExported drawings are saved as:\n- `./assets/drawings/drawing-{timestamp}.svg`\n- Inserted as `![Drawing](./assets/drawings/drawing-xxx.svg)`\n- Fully scalable and editable (SVG format)\n\n### Use Cases\n\n**Brainstorming:**\n- Mind maps\n- Concept diagrams\n- Flowcharts\n\n**Teaching:**\n- Annotate screenshots\n- Sketch explanations\n- Draw diagrams\n\n**Design:**\n- UI wireframes\n- Architecture sketches\n- Visual notes\n\n## ğŸ“‚ Asset Org",
    "searchText": "media guide media guide: photos, audio, drawings & more\n\nframe codex treats **all media as first-class knowledge strands** photos assets audio drawings jpg timestamp drawing svg upload radial menu click zoom media voice assets photos radial menu media guide audio drawings golden gate guide photos photos audio frame codex saved assets alt text"
  },
  {
    "path": "weaves/wiki/weave.yaml",
    "name": "weave.yaml",
    "type": "file",
    "metadata": {
      "slug": "wiki",
      "title": "Frame Codex Wiki",
      "description": "Complete documentation and technical architecture for Frame Codex, OpenStrand, and the knowledge organization system",
      "scope": "This weave contains all meta-documentation about Frame Codex itself:\n- How the Codex works (architecture, indexing, caching)\n- Contribution guides and schemas\n- OpenStrand integration details\n- Development and deployment guides\n",
      "boundaries": "This weave does NOT contain:\n- Actual knowledge content (see other weaves)\n- User-contributed strands (those go in subject-specific weaves)\n",
      "looms": [
        "architecture",
        "contributing",
        "development"
      ],
      "metadata": {
        "domain": "meta-documentation",
        "audience": [
          "contributors",
          "developers",
          "maintainers"
        ],
        "license": "CC-BY-4.0"
      },
      "tags": [
        "wiki",
        "documentation",
        "meta",
        "architecture",
        "contributing"
      ],
      "publishing": {
        "status": "published",
        "maintainers": [
          "jddunn"
        ]
      },
      "summary": "slug: wiki\ntitle: \"Frame Codex Wiki\"\ndescription: \"Complete documentation and technical architecture for Frame Codex, OpenStrand, and the knowledge organization system\"\n\nscope: |\n  This weave contains all meta-documentation about Frame Codex itself:\n  - How the Codex works (architecture, indexing...",
      "autoGenerated": {
        "keywords": [
          "documentation",
          "meta",
          "technical",
          "contains",
          "maintainers",
          "codex",
          "wiki",
          "development",
          "openstrand",
          "contribution",
          "deployment",
          "contributed",
          "subject",
          "audience",
          "contributors"
        ],
        "phrases": [
          "frame codex",
          "codex wiki",
          "meta documentation",
          "slug wiki",
          "wiki title",
          "title frame",
          "wiki description",
          "description complete",
          "complete documentation",
          "documentation technical"
        ],
        "subjects": [],
        "topics": [],
        "difficulty": "intermediate",
        "confidence": {},
        "readingLevel": 0,
        "readabilityScore": 0,
        "statistics": {},
        "entities": {
          "people": [],
          "places": [],
          "organizations": [],
          "topics": []
        },
        "lastIndexed": "2025-12-01T07:58:08.018Z"
      }
    },
    "validation": {
      "valid": true,
      "errors": [],
      "warnings": [],
      "suggestions": [
        "Add unique ID (UUID recommended)",
        "Add version number (semver format)",
        "Consider adding relationships (requires, references, seeAlso)",
        "Auto-detected subjects: ",
        "Auto-detected topics: ",
        "Suggested difficulty: intermediate",
        "Key phrases found: frame codex, codex wiki, meta documentation"
      ]
    },
    "content": "slug: wiki\ntitle: \"Frame Codex Wiki\"\ndescription: \"Complete documentation and technical architecture for Frame Codex, OpenStrand, and the knowledge organization system\"\n\nscope: |\n  This weave contains all meta-documentation about Frame Codex itself:\n  - How the Codex works (architecture, indexing, caching)\n  - Contribution guides and schemas\n  - OpenStrand integration details\n  - Development and deployment guides\n\nboundaries: |\n  This weave does NOT contain:\n  - Actual knowledge content (see other weaves)\n  - User-contributed strands (those go in subject-specific weaves)\n\nlooms:\n  - architecture\n  - contributing\n  - development\n\nmetadata:\n  domain: meta-documentation\n  audience: [contributors, developers, maintainers]\n  license: CC-BY-4.0\n\ntags: [wiki, documentation, meta, architecture, contributing]\n\npublishing:\n  status: published\n  maintainers: [jddunn]\n\n",
    "searchText": "frame codex wiki slug: wiki\ntitle: \"frame codex wiki\"\ndescription: \"complete documentation and technical architecture for frame codex, openstrand, and the knowledge organization system\"\n\nscope: |\n  this weave contains all meta-documentation about frame codex itself:\n  - how the codex works (architecture, indexing... documentation meta technical contains maintainers codex wiki development openstrand contribution deployment contributed subject audience contributors frame codex codex wiki meta documentation slug wiki wiki title title frame wiki description description complete complete documentation documentation technical"
  },
  {
    "path": "schema/loom.schema.yaml",
    "name": "loom.schema.yaml",
    "type": "file",
    "metadata": {
      "$schema": "https://json-schema.org/draft/2020-12/schema",
      "title": "Loom",
      "type": "object",
      "required": [
        "slug",
        "title"
      ],
      "properties": {
        "slug": {
          "type": "string",
          "pattern": "^[a-z0-9-]+$"
        },
        "title": {
          "type": "string"
        },
        "summary": {
          "type": "string"
        },
        "tags": {
          "type": "array",
          "items": {
            "type": "string"
          }
        },
        "ordering": {
          "type": "string",
          "enum": [
            "manual",
            "alpha",
            "date",
            "weight"
          ],
          "default": "manual"
        },
        "relationships": {
          "type": "array",
          "items": {
            "type": "object",
            "properties": {
              "targetSlug": {
                "type": "string"
              },
              "type": {
                "type": "string",
                "enum": [
                  "follows",
                  "parallels",
                  "contrasts",
                  "extends",
                  "applies"
                ]
              },
              "strength": {
                "type": "number",
                "minimum": 0,
                "maximum": 1
              }
            }
          }
        }
      },
      "summary": "$schema: \"https://json-schema.org/draft/2020-12/schema\"\ntitle: Loom\ntype: object\nrequired: [slug, title]\nproperties:\n  slug:\n    type: string\n    pattern: \"^[a-z0-9-]+$\"\n  title:\n    type: string\n  summary:\n    type: string\n  tags:\n    type: array\n    items: { type: string }\n  ordering:\n    type:...",
      "autoGenerated": {
        "keywords": [
          "string",
          "type",
          "properties",
          "array",
          "schema",
          "object",
          "2020",
          "org",
          "pattern",
          "ordering",
          "enum",
          "slug",
          "items",
          "required",
          "manual"
        ],
        "phrases": [
          "type string",
          "type object",
          "type array",
          "array items",
          "items type",
          "schema https",
          "https json",
          "json schema",
          "schema org",
          "org draft"
        ],
        "subjects": [],
        "topics": [],
        "difficulty": "intermediate",
        "confidence": {},
        "readingLevel": 0,
        "readabilityScore": 0,
        "statistics": {},
        "entities": {
          "people": [],
          "places": [],
          "organizations": [],
          "topics": []
        },
        "lastIndexed": "2025-12-01T07:58:08.076Z"
      }
    },
    "validation": {
      "valid": true,
      "errors": [],
      "warnings": [],
      "suggestions": [
        "Add unique ID (UUID recommended)",
        "Add version number (semver format)",
        "Consider adding tags: string, type, properties, array, schema",
        "Consider adding relationships (requires, references, seeAlso)",
        "Auto-detected subjects: ",
        "Auto-detected topics: ",
        "Suggested difficulty: intermediate",
        "Key phrases found: type string, type object, type array"
      ]
    },
    "content": "$schema: \"https://json-schema.org/draft/2020-12/schema\"\ntitle: Loom\ntype: object\nrequired: [slug, title]\nproperties:\n  slug:\n    type: string\n    pattern: \"^[a-z0-9-]+$\"\n  title:\n    type: string\n  summary:\n    type: string\n  tags:\n    type: array\n    items: { type: string }\n  ordering:\n    type: string\n    enum: [manual, alpha, date, weight]\n    default: manual\n  relationships:\n    type: array\n    items:\n      type: object\n      properties:\n        targetSlug: { type: string }\n        type:\n          type: string\n          enum: [follows, parallels, contrasts, extends, applies]\n        strength: { type: number, minimum: 0, maximum: 1 }\n\n\n",
    "searchText": "loom $schema: \"https://json-schema.org/draft/2020-12/schema\"\ntitle: loom\ntype: object\nrequired: [slug, title]\nproperties:\n  slug:\n    type: string\n    pattern: \"^[a-z0-9-]+$\"\n  title:\n    type: string\n  summary:\n    type: string\n  tags:\n    type: array\n    items: { type: string }\n  ordering:\n    type:... string type properties array schema object 2020 org pattern ordering enum slug items required manual type string type object type array array items items type schema https https json json schema schema org org draft"
  },
  {
    "path": "schema/strand.schema.yaml",
    "name": "strand.schema.yaml",
    "type": "file",
    "metadata": {
      "$schema": "https://json-schema.org/draft/2020-12/schema",
      "title": "StrandFrontmatter",
      "type": "object",
      "required": [
        "id",
        "slug",
        "title",
        "version",
        "contentType"
      ],
      "properties": {
        "id": {
          "type": "string",
          "format": "uuid"
        },
        "slug": {
          "type": "string",
          "pattern": "^[a-z0-9-]+$"
        },
        "title": {
          "type": "string"
        },
        "summary": {
          "type": "string",
          "description": "Deprecated alias retained for backward compatibility. Use extractiveSummary instead."
        },
        "extractiveSummary": {
          "type": "string",
          "description": "Deterministic summary generated by the static NLP pipeline (TF-IDF, n-grams)."
        },
        "aiSummary": {
          "type": "string",
          "description": "Optional abstractive summary produced by LLM providers."
        },
        "notes": {
          "type": "array",
          "items": {
            "type": "string"
          },
          "description": "Curated bullet notes for this strand."
        },
        "version": {
          "type": "string",
          "pattern": "^\\d+\\.\\d+\\.\\d+$"
        },
        "contentType": {
          "type": "string",
          "enum": [
            "lesson",
            "reference",
            "exercise",
            "assessment",
            "project",
            "discussion",
            "resource"
          ]
        },
        "difficulty": {
          "type": "object",
          "properties": {
            "overall": {
              "enum": [
                "beginner",
                "intermediate",
                "advanced",
                "expert"
              ]
            },
            "cognitive": {
              "type": "number",
              "minimum": 1,
              "maximum": 10
            },
            "prerequisites": {
              "type": "number",
              "minimum": 0,
              "maximum": 10
            },
            "conceptual": {
              "type": "number",
              "minimum": 1,
              "maximum": 10
            }
          }
        },
        "taxonomy": {
          "type": "object",
          "properties": {
            "subject": {
              "type": "array",
              "items": {
                "type": "string"
              }
            },
            "topic": {
              "type": "array",
              "items": {
                "type": "string"
              }
            },
            "subtopic": {
              "type": "array",
              "items": {
                "type": "string"
              }
            },
            "concepts": {
              "type": "array",
              "items": {
                "type": "object",
                "properties": {
                  "term": {
                    "type": "string"
                  },
                  "weight": {
                    "type": "number",
                    "minimum": 0,
                    "maximum": 1
                  }
                }
              }
            }
          }
        },
        "relationships": {
          "type": "array",
          "items": {
            "type": "object",
            "properties": {
              "targetSlug": {
                "type": "string"
              },
              "type": {
                "enum": [
                  "follows",
                  "parallels",
                  "contrasts",
                  "extends",
                  "applies",
                  "synthesizes"
                ]
              },
              "strength": {
                "type": "number",
                "minimum": 0,
                "maximum": 1
              },
              "bidirectional": {
                "type": "boolean",
                "default": false
              }
            }
          }
        },
        "publishing": {
          "type": "object",
          "properties": {
            "status": {
              "enum": [
                "draft",
                "review",
                "published",
                "archived"
              ]
            },
            "license": {
              "type": "string",
              "default": "MIT"
            }
          }
        }
      },
      "summary": "Use extractiveSummary instead.\"\n  extractiveSummary:\n    type: string\n    description: \"Deterministic summary generated by the static NLP pipeline (TF-IDF, n-grams).\"\n  aiSummary:\n    type: string\n    description: \"Optional abstractive summary produced by LLM providers.\"\n  notes:\n    type: array\n...",
      "autoGenerated": {
        "keywords": [
          "type",
          "string",
          "array",
          "properties",
          "extractivesummary",
          "minimum",
          "maximum",
          "object",
          "enum",
          "description",
          "items",
          "strandfrontmatter",
          "deterministic",
          "aisummary",
          "abstractive"
        ],
        "phrases": [
          "type string",
          "type array",
          "string description",
          "type object",
          "array items",
          "items type",
          "object properties",
          "type minimum",
          "minimum maximum",
          "extractivesummary extractivesummary"
        ],
        "subjects": [],
        "topics": [],
        "difficulty": "intermediate",
        "confidence": {},
        "readingLevel": 0,
        "readabilityScore": 0,
        "statistics": {},
        "entities": {
          "people": [
            "[lesson,"
          ],
          "places": [],
          "organizations": [],
          "topics": [
            "[lesson,"
          ]
        },
        "lastIndexed": "2025-12-01T07:58:08.228Z"
      }
    },
    "validation": {
      "valid": true,
      "errors": [],
      "warnings": [],
      "suggestions": [
        "Add unique ID (UUID recommended)",
        "Add version number (semver format)",
        "Consider adding tags: type, string, array, properties, extractivesummary",
        "Consider adding relationships (requires, references, seeAlso)",
        "Auto-detected subjects: ",
        "Auto-detected topics: ",
        "Suggested difficulty: intermediate",
        "Key phrases found: type string, type array, string description"
      ]
    },
    "content": "$schema: \"https://json-schema.org/draft/2020-12/schema\"\ntitle: StrandFrontmatter\ntype: object\nrequired: [id, slug, title, version, contentType]\nproperties:\n  id: { type: string, format: uuid }\n  slug: { type: string, pattern: \"^[a-z0-9-]+$\" }\n  title: { type: string }\n  summary:\n    type: string\n    description: \"Deprecated alias retained for backward compatibility. Use extractiveSummary instead.\"\n  extractiveSummary:\n    type: string\n    description: \"Deterministic summary generated by the static NLP pipeline (TF-IDF, n-grams).\"\n  aiSummary:\n    type: string\n    description: \"Optional abstractive summary produced by LLM providers.\"\n  notes:\n    type: array\n    items: { type: string }\n    description: \"Curated bullet notes for this strand.\"\n  version: { type: string, pattern: \"^\\\\d+\\\\.\\\\d+\\\\.\\\\d+$\" }\n  contentType:\n    type: string\n    enum: [lesson, reference, exercise, assessment, project, discussion, resource]\n  difficulty:\n    type: object\n    properties:\n      overall: { enum: [beginner, intermediate, advanced, expert] }\n      cognitive: { type: number, minimum: 1, maximum: 10 }\n      prerequisites: { type: number, minimum: 0, maximum: 10 }\n      conceptual: { type: number, minimum: 1, maximum: 10 }\n  taxonomy:\n    type: object\n    properties:\n      subject: { type: array, items: { type: string } }\n      topic: { type: array, items: { type: string } }\n      subtopic: { type: array, items: { type: string } }\n      concepts:\n        type: array\n        items:\n          type: object\n          properties:\n            term: { type: string }\n            weight: { type: number, minimum: 0, maximum: 1 }\n  relationships:\n    type: array\n    items:\n      type: object\n      properties:\n        targetSlug: { type: string }\n        type: { enum: [follows, parallels, contrasts, extends, applies, synthesizes] }\n        strength: { type: number, minimum: 0, maximum: 1 }\n        bidirectional: { type: boolean, default: false }\n  publishing:\n    type: object\n    properties:\n      status: { enum: [draft, review, published, archived] }\n      license: { type: string, default: MIT }\n",
    "searchText": "strandfrontmatter use extractivesummary instead.\"\n  extractivesummary:\n    type: string\n    description: \"deterministic summary generated by the static nlp pipeline (tf-idf, n-grams).\"\n  aisummary:\n    type: string\n    description: \"optional abstractive summary produced by llm providers.\"\n  notes:\n    type: array\n... type string array properties extractivesummary minimum maximum object enum description items strandfrontmatter deterministic aisummary abstractive type string type array string description type object array items items type object properties type minimum minimum maximum extractivesummary extractivesummary"
  },
  {
    "path": "schema/weave.schema.yaml",
    "name": "weave.schema.yaml",
    "type": "file",
    "metadata": {
      "$schema": "https://json-schema.org/draft/2020-12/schema",
      "title": "Weave",
      "type": "object",
      "required": [
        "slug",
        "title"
      ],
      "properties": {
        "slug": {
          "type": "string",
          "pattern": "^[a-z0-9-]+$"
        },
        "title": {
          "type": "string",
          "minLength": 3
        },
        "description": {
          "type": "string"
        },
        "maintainedBy": {
          "type": "string"
        },
        "license": {
          "type": "string",
          "default": "MIT"
        },
        "tags": {
          "type": "array",
          "items": {
            "type": "string"
          }
        }
      },
      "summary": "$schema: \"https://json-schema.org/draft/2020-12/schema\"\ntitle: Weave\ntype: object\nrequired: [slug, title]\nproperties:\n  slug:\n    type: string\n    pattern: \"^[a-z0-9-]+$\"\n  title:\n    type: string\n    minLength: 3\n  description:\n    type: string\n  maintainedBy:\n    type: string\n  license:\n    typ...",
      "autoGenerated": {
        "keywords": [
          "string",
          "type",
          "minlength",
          "schema",
          "maintainedby",
          "2020",
          "org",
          "slug",
          "properties",
          "pattern",
          "object",
          "required",
          "license",
          "description",
          "weave"
        ],
        "phrases": [
          "type string",
          "schema https",
          "https json",
          "json schema",
          "schema org",
          "org draft",
          "draft 2020",
          "2020 schema",
          "schema title",
          "title weave"
        ],
        "subjects": [],
        "topics": [],
        "difficulty": "intermediate",
        "confidence": {},
        "readingLevel": 0,
        "readabilityScore": 0,
        "statistics": {},
        "entities": {
          "people": [],
          "places": [],
          "organizations": [],
          "topics": []
        },
        "lastIndexed": "2025-12-01T07:58:08.271Z"
      }
    },
    "validation": {
      "valid": true,
      "errors": [],
      "warnings": [],
      "suggestions": [
        "Add unique ID (UUID recommended)",
        "Add version number (semver format)",
        "Consider adding tags: string, type, minlength, schema, maintainedby",
        "Consider adding relationships (requires, references, seeAlso)",
        "Auto-detected subjects: ",
        "Auto-detected topics: ",
        "Suggested difficulty: intermediate",
        "Key phrases found: type string, schema https, https json"
      ]
    },
    "content": "$schema: \"https://json-schema.org/draft/2020-12/schema\"\ntitle: Weave\ntype: object\nrequired: [slug, title]\nproperties:\n  slug:\n    type: string\n    pattern: \"^[a-z0-9-]+$\"\n  title:\n    type: string\n    minLength: 3\n  description:\n    type: string\n  maintainedBy:\n    type: string\n  license:\n    type: string\n    default: MIT\n  tags:\n    type: array\n    items:\n      type: string\n\n\n",
    "searchText": "weave $schema: \"https://json-schema.org/draft/2020-12/schema\"\ntitle: weave\ntype: object\nrequired: [slug, title]\nproperties:\n  slug:\n    type: string\n    pattern: \"^[a-z0-9-]+$\"\n  title:\n    type: string\n    minlength: 3\n  description:\n    type: string\n  maintainedby:\n    type: string\n  license:\n    typ... string type minlength schema maintainedby 2020 org slug properties pattern object required license description weave type string schema https https json json schema schema org org draft draft 2020 2020 schema schema title title weave"
  },
  {
    "path": "docs/CHANGELOG_SYSTEM.md",
    "name": "CHANGELOG_SYSTEM.md",
    "type": "file",
    "metadata": {
      "id": "changelog-system-guide",
      "slug": "changelog-system",
      "title": "Frame Codex Changelog System",
      "summary": "Automated changelog and activity tracking using git commits and GitHub API",
      "version": "1.0.0",
      "contentType": "markdown",
      "difficulty": "beginner",
      "taxonomy": {
        "subjects": [
          "technology"
        ],
        "topics": [
          "automation",
          "ci-cd"
        ]
      },
      "tags": [
        "changelog",
        "automation",
        "github-actions",
        "git",
        "graphql"
      ],
      "relationships": {
        "references": [
          "development-guide"
        ]
      },
      "publishing": {
        "status": "published"
      },
      "autoGenerated": {
        "keywords": [
          "git",
          "commits",
          "changelog",
          "2025",
          "activity",
          "issues",
          "commit",
          "conventional",
          "fix",
          "gh_pat",
          "feat",
          "changes",
          "codex",
          "author",
          "generate"
        ],
        "phrases": [
          "codex git",
          "github com",
          "frame codex",
          "codex issues",
          "framersai codex",
          "github actions",
          "git changelog",
          "conventional commit",
          "yyyy json",
          "https github"
        ],
        "subjects": [
          "technology"
        ],
        "topics": [
          "automation",
          "ci-cd"
        ],
        "difficulty": "beginner",
        "confidence": {},
        "readingLevel": 0,
        "readabilityScore": 0,
        "statistics": {},
        "entities": {
          "people": [
            "\"John Doe\",",
            "\"John Doe\")'"
          ],
          "places": [],
          "organizations": [
            "GitHub",
            "GitHub",
            "**Fetches GitHub",
            "AI",
            "GitHub",
            "GitHub",
            "Storage & Performance",
            "ups",
            "GitHub",
            "- [GitHub"
          ],
          "topics": [
            "- [GitHub",
            "- [GitHub",
            "GitHub",
            "ups",
            "Storage & Performance",
            "GitHub",
            "GitHub",
            "AI",
            "**Fetches GitHub",
            "GitHub",
            "GitHub",
            "\"John Doe\")'",
            "\"John Doe\","
          ]
        },
        "lastIndexed": "2025-12-01T07:58:08.768Z"
      }
    },
    "validation": {
      "valid": true,
      "errors": [],
      "warnings": [],
      "suggestions": [
        "Key phrases found: codex git, github com, frame codex"
      ]
    },
    "content": "\n# Frame Codex Changelog System\n\nFrame Codex automatically tracks and records all changes, issues, and pull requests in a structured, machine-readable format.\n\n## Overview\n\nThe changelog system runs daily via GitHub Actions and generates:\n\n1. **Git Changelog**: Parsed conventional commits with metadata\n2. **Issue Activity**: Created, closed, and merged issues/PRs\n3. **JSON Snapshots**: One file per day for easy querying\n\nAll history is stored in `codex-history/` and committed to the repository.\n\n## Why This Matters\n\n### For Humans\n\n- **Transparency**: See exactly what changed and when\n- **Accountability**: Track who contributed what\n- **Discovery**: Find related changes quickly\n\n### For AI\n\n- **Structured Data**: Consistent JSON schema for LLM consumption\n- **Contextual**: Links to commits, issues, PRs for deep dives\n- **Queryable**: Filter by date, type, author, or label\n\n## How It Works\n\n### Daily Automation\n\nEvery day at 00:00 UTC, a GitHub Actions workflow:\n\n1. **Fetches Git History**\n   - Parses last 7 days of commits\n   - Extracts conventional commit metadata\n   - Writes `codex-history/git/YYYY-MM-DD.json`\n\n2. **Fetches GitHub Activity** (if `GH_PAT` is set)\n   - Queries GraphQL API for yesterday's activity\n   - Collects created/closed issues and merged PRs\n   - Writes `codex-history/issues/YYYY-MM-DD.json`\n\n3. **Commits Changes**\n   - Adds new JSON files\n   - Pushes to `master` branch\n\n### Manual Generation\n\nYou can also generate history manually:\n\n```bash\ncd apps/codex\n\n# Git changelog for a date range\nnode scripts/generate-changelog.js --since 2025-01-01\n\n# Issue activity (requires GH_PAT)\nGH_PAT=ghp_xxx node scripts/fetch-issue-activity.js --since 2025-01-01\n```\n\n## Data Formats\n\n### Git Changelog\n\n`codex-history/git/YYYY-MM-DD.json`:\n\n```json\n{\n  \"date\": \"2025-01-15\",\n  \"totalCommits\": 5,\n  \"byType\": {\n    \"feat\": [\n      {\n        \"sha\": \"abc1234\",\n        \"author\": \"John Doe\",\n        \"date\": \"2025-01-15T10:30:00Z\",\n        \"url\": \"https://github.com/framersai/codex/commit/abc1234\",\n        \"type\": \"feat\",\n        \"scope\": \"indexer\",\n        \"description\": \"add SQL caching\"\n      }\n    ],\n    \"fix\": [...],\n    \"chore\": [...]\n  },\n  \"commits\": [...]\n}\n```\n\n### Issue Activity\n\n`codex-history/issues/YYYY-MM-DD.json`:\n\n```json\n{\n  \"date\": \"2025-01-15\",\n  \"repository\": \"framersai/codex\",\n  \"summary\": {\n    \"issuesCreated\": 2,\n    \"issuesClosed\": 1,\n    \"prsMerged\": 3,\n    \"total\": 6\n  },\n  \"created\": [\n    {\n      \"number\": 42,\n      \"title\": \"Add new feature\",\n      \"url\": \"https://github.com/framersai/codex/issues/42\",\n      \"createdAt\": \"2025-01-15T14:20:00Z\",\n      \"author\": \"johndoe\",\n      \"labels\": [\"enhancement\"]\n    }\n  ],\n  \"closed\": [...],\n  \"merged\": [...]\n}\n```\n\n## Conventional Commits\n\nFor best results, use conventional commit format:\n\n```\ntype(scope): description\n\nOptional body with more details\n```\n\n### Commit Types\n\n- `feat`: New feature\n- `fix`: Bug fix\n- `docs`: Documentation only\n- `chore`: Maintenance (deps, config, etc.)\n- `refactor`: Code refactoring\n- `test`: Tests\n- `ci`: CI/CD changes\n- `perf`: Performance improvements\n\n### Examples\n\n```bash\n# Good\ngit commit -m \"feat(indexer): add SQL caching for 10x speedup\"\ngit commit -m \"fix(validator): handle missing required fields\"\ngit commit -m \"docs: update submission guide with ECA fields\"\n\n# Also fine (fallback to \"other\" type)\ngit commit -m \"Update README\"\n```\n\n## Querying History\n\n### Command Line (jq)\n\n```bash\n# Find all features added in January\njq '.commits[] | select(.type == \"feat\")' codex-history/git/2025-01-*.json\n\n# Count PRs merged per day\njq '.summary.prsMerged' codex-history/issues/*.json\n\n# Get commits by author\njq '.commits[] | select(.author == \"John Doe\")' codex-history/git/*.json\n\n# Find issues with specific label\njq '.created[] | select(.labels | contains([\"bug\"]))' codex-history/issues/*.json\n```\n\n### JavaScript/TypeScript\n\n```typescript\nimport fs from 'fs'\nimport path from 'path'\n\n// Load all git changelogs for a month\nfunction loadMonth(year: number, month: number) {\n  const dir = 'codex-history/git'\n  const files = fs.readdirSync(dir)\n    .filter(f => f.startsWith(`${year}-${month.toString().padStart(2, '0')}`))\n    .map(f => JSON.parse(fs.readFileSync(path.join(dir, f), 'utf-8')))\n  \n  return files\n}\n\n// Get all features\nconst january = loadMonth(2025, 1)\nconst features = january.flatMap(day => \n  day.commits.filter(c => c.type === 'feat')\n)\n\nconsole.log(`${features.length} features added in January`)\n```\n\n### AI Prompts\n\n> \"Summarize the changes in Frame Codex for the week of January 15-21, 2025. Focus on new features and bug fixes.\"\n\nThe AI can read the relevant JSON files and generate a comprehensive summary.\n\n## Configuration\n\n### GitHub Secrets\n\nAdd to `framersai/codex` repository settings:\n\n**Required:**\n- `GH_PAT`: GitHub Personal Access Token with `repo` scope\n  - Used for issue/PR activity tracking\n  - Generate at: https://github.com/settings/tokens/new?scopes=repo\n\n**Optional:**\n- None (git chang",
    "searchText": "frame codex changelog system automated changelog and activity tracking using git commits and github api git commits changelog 2025 activity issues commit conventional fix gh_pat feat changes codex author generate codex git github com frame codex codex issues framersai codex github actions git changelog conventional commit yyyy json https github"
  },
  {
    "path": "docs/DEVELOPMENT.md",
    "name": "DEVELOPMENT.md",
    "type": "file",
    "metadata": {
      "title": "DEVELOPMENT",
      "summary": "**Run Initial Catalog** (categorizes ALL existing content)\n\n\nThis will:\n- Scan all markdown files in , , \n- Extract keywords using TF-IDF\n- Auto-categorize using NLP (no LLM, pure statistical)\n- Generate  (searchable index)\n- Generate  (analytics)\n- Output validation errors/warnings/suggestions\n\n...",
      "autoGenerated": {
        "keywords": [
          "run",
          "const",
          "index",
          "loom",
          "cache",
          "null",
          "npm",
          "bash",
          "scripts",
          "not",
          "seconds",
          "await",
          "keywords",
          "integer",
          "cachekey"
        ],
        "phrases": [
          "not null",
          "npm run",
          "run index",
          "index validate",
          "static nlp",
          "auto merge",
          "integer not",
          "loom strands",
          "apps codex",
          "auto index"
        ],
        "subjects": [],
        "topics": [],
        "difficulty": "intermediate",
        "confidence": {},
        "readingLevel": 0,
        "readabilityScore": 0,
        "statistics": {},
        "entities": {
          "people": [
            "PAT"
          ],
          "places": [
            "state",
            "dist/",
            "dist/auto-"
          ],
          "organizations": [
            "GitHub",
            "Variables & Secrets",
            "Required GitHub",
            "GitHub",
            "Local Development",
            "GitHub",
            "Via GitHub",
            "GitHub",
            "**GitHub",
            "Authentication & PR"
          ],
          "topics": [
            "GitHub",
            "GitHub",
            "(GitHub",
            "GitHub",
            "GitHub\":",
            "GitHub",
            "- GitHub",
            "GitHub",
            "GitHub",
            "Provides GitHub",
            "Authentication & PR",
            "**GitHub",
            "GitHub",
            "Via GitHub",
            "GitHub"
          ]
        },
        "lastIndexed": "2025-12-01T07:58:10.219Z"
      }
    },
    "validation": {
      "valid": true,
      "errors": [],
      "warnings": [],
      "suggestions": [
        "Add unique ID (UUID recommended)",
        "Add version number (semver format)",
        "Consider adding tags: run, const, index, loom, cache",
        "Consider adding relationships (requires, references, seeAlso)",
        "Auto-detected subjects: ",
        "Auto-detected topics: ",
        "Suggested difficulty: intermediate",
        "Key phrases found: not null, npm run, run index"
      ]
    },
    "content": "# Frame Codex Development Guide\n\n## Initial Setup & Cataloging\n\n### First-Time Setup\n\n1. **Install Dependencies**\n```bash\ncd apps/codex\nnpm install\n```\n\n2. **Run Initial Catalog** (categorizes ALL existing content)\n```bash\nnpm run index -- --validate\n```\n\nThis will:\n- Scan all markdown files in `weaves/`, `docs/`, `wiki/`\n- Extract keywords using TF-IDF\n- Auto-categorize using NLP (no LLM, pure statistical)\n- Generate `codex-index.json` (searchable index)\n- Generate `codex-report.json` (analytics)\n- Output validation errors/warnings/suggestions\n\n**First run takes ~30 seconds for 100 files**\n\n### How It Works Subsequently\n\n**Automatic on Every PR Merge:**\n\n1. GitHub Actions triggers `build-index.yml` on push to `main`\n2. Runs `npm run index -- --validate` (static NLP only)\n3. Generates updated index files\n4. Pushes to `index` branch for consumption\n5. **No AI/LLM calls** - pure TF-IDF, n-grams, vocabulary matching\n\n**Static NLP Tools Used:**\n- **TF-IDF**: Keyword extraction (no external API)\n- **N-gram extraction**: Common phrases (local computation)\n- **Vocabulary matching**: Controlled taxonomy (regex/string matching)\n- **Readability scoring**: Flesch-Kincaid (formula-based)\n- **Sentiment heuristics**: Simple keyword patterns\n\n**Cost: $0** - All processing is local/in-CI\n\n---\n\n## Environment Variables & Secrets\n\n### Required GitHub Secrets\n\nAdd to `framersai/codex` repository settings:\n\n```bash\n# Required for auto-merge workflow\nGH_PAT=ghp_xxxxxxxxxxxxxxxxxxxx  # GitHub Personal Access Token (repo scope)\n\n# AI Enhancement (OPTIONAL - only if you want AI-powered PR analysis)\nOPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxx\n\n# Auto-merge control (default: false - requires manual approval)\nAUTO_CATALOG_MERGE=false  # Set to 'true' to auto-merge re-catalog PRs\n\n# Configuration (optional)\nAI_PROVIDER=disabled  # Set to 'disabled' to skip AI entirely\n```\n\n### Secret Configuration\n\n**To enable AI enhancement:**\n```bash\nOPENAI_API_KEY=sk-...\n```\n\n**To enable auto-merge for re-catalog PRs:**\n```bash\nAUTO_CATALOG_MERGE=true\n# Default: false (requires manual approval)\n# Recommended: keep false to review metadata changes\n```\n\n**To disable AI enhancement:**\n```bash\nAI_PROVIDER=disabled\n# Or just don't set OPENAI_API_KEY\n```\n\n### Local Development\n\nCreate `.env` in `apps/codex/`:\n\n```bash\n# Optional - only for testing AI enhancement locally\nOPENAI_API_KEY=sk-...\n# or\nANTHROPIC_API_KEY=sk-ant-...\nAI_PROVIDER=openai\n```\n\n**Note:** The indexer and validator work WITHOUT any API keys. AI is only for optional PR enhancement.\n\n---\n\n## Triggering a Full Re-Catalog\n\n### Method 1: Automated Script (Recommended)\n\n```bash\ncd apps/codex\nchmod +x scripts/retrigger-full-catalog.sh\n\n# Dry run first (see what would change)\n./scripts/retrigger-full-catalog.sh --dry-run\n\n# Create PR with changes (requires manual approval)\n./scripts/retrigger-full-catalog.sh\n\n# Force auto-merge (one-time override)\n./scripts/retrigger-full-catalog.sh --auto-merge\n```\n\n**What it does:**\n1. Runs full static NLP analysis on ALL files\n2. Creates branch: `catalog/full-reindex-{timestamp}`\n3. Commits updated index files\n4. Creates PR with detailed summary\n5. **Waits for manual approval** (unless `AUTO_CATALOG_MERGE=true`)\n\n**Requirements:**\n- `GH_PAT` environment variable\n\n### Method 2: GitHub Actions Trigger\n\n```bash\n# Via GitHub CLI\ngh workflow run build-index.yml --repo framersai/codex\n\n# Or via web UI\n# Go to: https://github.com/framersai/codex/actions/workflows/build-index.yml\n# Click \"Run workflow\" â†’ \"Run workflow\"\n```\n\n**What it does:**\n- Runs indexer in CI\n- Pushes directly to `index` branch (no PR)\n- Updates live immediately\n\n### Method 3: Local Re-Index\n\n```bash\ncd apps/codex\nnpm run index -- --validate\n\n# Review changes\ncat codex-report.json | jq '.summary'\n\n# Commit manually\ngit add codex-index.json codex-report.json\ngit commit -m \"chore: re-index all content\"\ngit push\n```\n\n**See full guide:** [RECATALOG_GUIDE.md](./RECATALOG_GUIDE.md)\n\n---\n\n## Search Artifacts (BM25 + MiniLM embeddings)\n\nFrame.devâ€™s advanced search UI consumes a separate static artifact, `codex-search.json`, which contains:\n\n- BM25 postings (term â†’ docId, term frequency)\n- Document metadata (path, weave, loom, summary, doc length)\n- Packed Float32 embeddings (all-MiniLM-L6-v2, mean pooled, normalized)\n\nGenerate it after the main index:\n\n```bash\ncd apps/codex\nnpm run build:search\n\n# Commit alongside codex-index.json to publish updated search data\ngit add codex-search.json\n```\n\nThis command uses `@xenova/transformers` entirely in Node.js (no Python, no API keys) and produces a fully static JSON blob that can be hosted on GitHub Pages or any CDN.\n\n---\n\n## SQL Cache Architecture\n\nFrame Codex uses [@framers/sql-storage-adapter](https://github.com/framersai/sql-storage-adapter) for intelligent incremental indexing.\n\n### How It Works\n\n**On First Run:**\n1. Creates `.cache/codex.db` (better-sqlite3 in CI, IndexedDB in browser)\n2. Analyzes ALL files with static NLP (TF-IDF, n-grams)\n3. Stores: file pat",
    "searchText": "development **run initial catalog** (categorizes all existing content)\n\n\nthis will:\n- scan all markdown files in , , \n- extract keywords using tf-idf\n- auto-categorize using nlp (no llm, pure statistical)\n- generate  (searchable index)\n- generate  (analytics)\n- output validation errors/warnings/suggestions\n\n... run const index loom cache null npm bash scripts not seconds await keywords integer cachekey not null npm run run index index validate static nlp auto merge integer not loom strands apps codex auto index"
  },
  {
    "path": "docs/NLP_VOCABULARY_SYSTEM.md",
    "name": "NLP_VOCABULARY_SYSTEM.md",
    "type": "file",
    "metadata": {
      "title": "NLP VOCABULARY SYSTEM",
      "summary": "NLP & Vocabulary System Documentation\n\nOverview\n\nThe Codex auto-indexer uses a sophisticated NLP pipeline for content classification, keyword extraction, and auto-tagging",
      "autoGenerated": {
        "keywords": [
          "txt",
          "terms",
          "weight",
          "categories",
          "vocabulary",
          "neural",
          "learning",
          "classification",
          "enhance",
          "machine",
          "words",
          "term",
          "matching",
          "files",
          "context"
        ],
        "phrases": [
          "machine learning",
          "best practices",
          "nlp vocabulary",
          "auto indexer",
          "vocabulary documentation",
          "documentation overview",
          "overview codex",
          "codex auto",
          "indexer uses",
          "uses sophisticated"
        ],
        "subjects": [],
        "topics": [],
        "difficulty": "intermediate",
        "confidence": {},
        "readingLevel": 0,
        "readabilityScore": 0,
        "statistics": {},
        "entities": {
          "people": [
            "clay |",
            "Claude/GPT-4"
          ],
          "places": [],
          "organizations": [
            "NLP & Vocabulary"
          ],
          "topics": [
            "NLP & Vocabulary",
            "Claude/GPT-4",
            "clay |"
          ]
        },
        "lastIndexed": "2025-12-01T07:58:10.982Z"
      }
    },
    "validation": {
      "valid": true,
      "errors": [],
      "warnings": [],
      "suggestions": [
        "Add unique ID (UUID recommended)",
        "Add version number (semver format)",
        "Consider adding tags: txt, terms, weight, categories, vocabulary",
        "Consider adding relationships (requires, references, seeAlso)",
        "Auto-detected subjects: ",
        "Auto-detected topics: ",
        "Suggested difficulty: intermediate",
        "Key phrases found: machine learning, best practices, nlp vocabulary"
      ]
    },
    "content": "# NLP & Vocabulary System Documentation\n\n## Overview\n\nThe Codex auto-indexer uses a sophisticated NLP pipeline for content classification, keyword extraction, and auto-tagging. This system combines:\n\n1. **External Vocabulary Files** - Extensible text files with domain-specific terms\n2. **Porter Stemmer** - Word normalization for better matching\n3. **N-gram Analysis** - Trigram â†’ Bigram â†’ Unigram weighted matching\n4. **Context-Aware Scoring** - Reduce false positives through contextual analysis\n5. **LLM Assistance** (optional) - AI-powered enhancement via `ai-enhance.js`\n\n## Architecture\n\n```\nvocab/\nâ”œâ”€â”€ subjects/           # Domain categories (8 files)\nâ”‚   â”œâ”€â”€ technology.txt  # Programming, frameworks, tools\nâ”‚   â”œâ”€â”€ ai.txt          # Machine learning, LLMs, neural nets\nâ”‚   â”œâ”€â”€ science.txt     # Research, physics, chemistry, biology\nâ”‚   â”œâ”€â”€ philosophy.txt  # Ethics, metaphysics, epistemology\nâ”‚   â”œâ”€â”€ knowledge.txt   # Documentation, learning, OpenStrand\nâ”‚   â”œâ”€â”€ design.txt      # UX/UI, visual design, accessibility\nâ”‚   â”œâ”€â”€ security.txt    # Encryption, auth, vulnerabilities\nâ”‚   â””â”€â”€ media.txt       # Images, video, audio, formats\nâ”œâ”€â”€ topics/             # Content type categories (5 files)\nâ”‚   â”œâ”€â”€ getting-started.txt\nâ”‚   â”œâ”€â”€ architecture.txt\nâ”‚   â”œâ”€â”€ api-reference.txt\nâ”‚   â”œâ”€â”€ best-practices.txt\nâ”‚   â””â”€â”€ troubleshooting.txt\nâ”œâ”€â”€ difficulty/         # Skill levels (4 files)\nâ”‚   â”œâ”€â”€ beginner.txt\nâ”‚   â”œâ”€â”€ intermediate.txt\nâ”‚   â”œâ”€â”€ advanced.txt\nâ”‚   â””â”€â”€ expert.txt\nâ””â”€â”€ stopwords.txt       # 500+ stop words for filtering\n```\n\n## N-gram Weighted Matching\n\nThe system prioritizes longer, more specific matches:\n\n| N-gram Type | Weight | Example |\n|-------------|--------|---------|\n| **Trigram** (3 words) | 3.0x | \"machine learning model\" |\n| **Bigram** (2 words) | 2.0x | \"neural network\" |\n| **Unigram** (1 word) | 1.0x | \"tensorflow\" |\n\n### Matching Logic\n\n```javascript\n// Trigrams checked first (highest specificity)\nif (trigramSet.has(\"domain driven design\")) â†’ weight = 3.0\n\n// Then bigrams\nif (bigramSet.has(\"clean architecture\")) â†’ weight = 2.0\n\n// Finally unigrams with stemming\nif (unigramSet.has(\"microservic\") || unigramSet.has(\"microservice\")) â†’ weight = 1.0\n\n// Hyphenated compound terms get 1.5x unigram weight\nif (allPartsMatch(\"event-driven\")) â†’ weight = 1.5\n```\n\n## Context-Aware Scoring\n\nTo avoid false positives (e.g., \"library\" matching programming when discussing a physical library), the system applies context adjustments:\n\n### Negative Context (Score Ã— 0.3)\n\n| Term | Negative Context Words |\n|------|----------------------|\n| library | physical, book, public, municipal, lending |\n| learning | curve, disability, difficulties, disorder |\n| framework | legal, regulatory, policy, theoretical |\n| model | fashion, role, scale, 3d, clay |\n| platform | train, station, political, diving |\n| cloud | weather, rain, storm, sky |\n\n### Positive Context (Score Ã— 1.5)\n\n| Term | Positive Context Words |\n|------|----------------------|\n| library | code, import, npm, package, install, dependency |\n| learning | machine, deep, model, neural, ai, training |\n| framework | web, software, javascript, python, backend |\n| model | machine, learning, neural, language, ai |\n| platform | cloud, software, development, api, saas |\n\n## Porter Stemmer\n\nAll terms are normalized using the Porter Stemming Algorithm:\n\n| Original | Stemmed |\n|----------|---------|\n| programming | program |\n| development | develop |\n| configuration | configur |\n| authentication | authent |\n| microservices | microservic |\n\nThis allows matching word variants automatically.\n\n## Adding Vocabulary Terms\n\nSimply add terms to the appropriate `.txt` file:\n\n```txt\n# vocab/subjects/technology.txt\n# One term per line. Lines starting with # are comments.\n\nkubernetes\nk8s\nhelm-chart\nistio\nservice-mesh\n```\n\n### Best Practices\n\n1. **Use hyphens** for compound terms: `machine-learning`, `event-driven`\n2. **Include variations**: `k8s`, `kubernetes`, `kube`\n3. **Add acronyms**: Both `API` and `application-programming-interface`\n4. **Use lowercase**: Normalization handles case automatically\n5. **Group related terms**: Keep related concepts together\n\n## LLM Enhancement (Optional)\n\nThe `ai-enhance.js` script uses Claude/GPT-4 to:\n\n1. **Auto-fill metadata** - Title, summary, tags\n2. **Suggest categories** - Subject, topic, difficulty\n3. **Detect quality issues** - Missing sections, unclear content\n4. **Generate summaries** - Extractive and abstractive\n\n### Usage\n\n```bash\n# Analyze specific files\nnode scripts/ai-enhance.js --files \"file1.md,file2.md\"\n\n# Apply safe fixes automatically\nnode scripts/ai-enhance.js --files \"file1.md\" --apply-safe-fixes\n```\n\n### Environment Variables\n\n```env\nOPENAI_API_KEY=sk-...\nANTHROPIC_API_KEY=sk-ant-...\nOPENROUTER_API_KEY=sk-or-...\nAI_PROVIDER=anthropic  # or 'openai', 'openrouter', 'disabled'\n```\n\n## Classification Output\n\nThe classifier returns:\n\n```javascript\n{\n  subjects: ['technology', 'ai'],\n  topics: ['architecture', 'best-practices'],\n  difficulty: 'intermedia",
    "searchText": "nlp vocabulary system nlp & vocabulary system documentation\n\noverview\n\nthe codex auto-indexer uses a sophisticated nlp pipeline for content classification, keyword extraction, and auto-tagging txt terms weight categories vocabulary neural learning classification enhance machine words term matching files context machine learning best practices nlp vocabulary auto indexer vocabulary documentation documentation overview overview codex codex auto indexer uses uses sophisticated"
  },
  {
    "path": "docs/RECATALOG_GUIDE.md",
    "name": "RECATALOG_GUIDE.md",
    "type": "file",
    "metadata": {
      "id": "recatalog-guide",
      "slug": "recatalog-guide",
      "title": "Frame Codex Re-Catalog Guide",
      "summary": "Complete guide to triggering full re-indexing and metadata updates for all Frame Codex content",
      "version": "1.0.0",
      "contentType": "markdown",
      "difficulty": "intermediate",
      "taxonomy": {
        "subjects": [
          "technology",
          "knowledge"
        ],
        "topics": [
          "deployment",
          "best-practices"
        ]
      },
      "tags": [
        "catalog",
        "indexing",
        "automation",
        "ci-cd",
        "metadata"
      ],
      "autoGenerated": {
        "keywords": [
          "catalog",
          "run",
          "retrigger",
          "validation",
          "report",
          "merge",
          "index",
          "full",
          "changes",
          "monthly",
          "avg",
          "review",
          "prs",
          "check",
          "codex"
        ],
        "phrases": [
          "full catalog",
          "auto merge",
          "scripts retrigger",
          "retrigger full",
          "codex report",
          "report json",
          "static nlp",
          "frame codex",
          "codex index",
          "index json"
        ],
        "subjects": [
          "technology",
          "knowledge"
        ],
        "topics": [
          "deployment",
          "best-practices"
        ],
        "difficulty": "intermediate",
        "confidence": {},
        "readingLevel": 0,
        "readabilityScore": 0,
        "statistics": {},
        "entities": {
          "people": [],
          "places": [],
          "organizations": [
            "GitHub",
            "GitHub",
            "GitHub",
            "Via GitHub",
            "GitHub",
            "GitHub",
            "GitHub"
          ],
          "topics": [
            "GitHub",
            "GitHub",
            "GitHub",
            "Via GitHub",
            "GitHub",
            "GitHub",
            "GitHub"
          ]
        },
        "lastIndexed": "2025-12-01T07:58:11.778Z"
      }
    },
    "validation": {
      "valid": true,
      "errors": [],
      "warnings": [],
      "suggestions": [
        "Consider adding relationships (requires, references, seeAlso)",
        "Key phrases found: full catalog, auto merge, scripts retrigger"
      ]
    },
    "content": "\n# Frame Codex Re-Catalog Guide\n\nThis guide explains how to trigger a complete re-indexing and metadata update for all Frame Codex content.\n\n---\n\n## When to Re-Catalog\n\nRun a full re-catalog when:\n\nâœ… **Initial setup** - First time setting up the repository  \nâœ… **Schema changes** - After updating validation rules or metadata schema  \nâœ… **Vocabulary updates** - After adding new subjects/topics to controlled vocabulary  \nâœ… **Bulk imports** - After importing large amounts of content  \nâœ… **Quality audit** - Periodic review of all content (monthly/quarterly)  \n\nâŒ **NOT needed for:**\n- Individual PR merges (automatic via GitHub Actions)\n- Small metadata fixes (handled by normal PR flow)\n- Content updates without schema changes\n\n---\n\n## Method 1: GitHub Actions (Recommended)\n\n### Via GitHub Web UI\n\n1. Go to https://github.com/framersai/codex/actions/workflows/build-index.yml\n2. Click **\"Run workflow\"** dropdown (top right)\n3. Select branch: `main`\n4. Click **\"Run workflow\"** button\n5. Wait ~1-2 minutes for completion\n\n### Via GitHub CLI\n\n```bash\ngh workflow run build-index.yml --repo framersai/codex\n```\n\n**What It Does:**\n- Runs `npm run index -- --validate` on ALL files\n- Generates `codex-index.json` and `codex-report.json`\n- Pushes to `index` branch (no PR needed)\n- Updates live immediately on frame.dev/codex\n\n**Cost:** $0 (static NLP only, no AI calls)\n\n---\n\n## Method 2: Local Script with PR Creation\n\n### Using the Re-Catalog Script\n\n```bash\ncd apps/codex\nchmod +x scripts/retrigger-full-catalog.sh\n./scripts/retrigger-full-catalog.sh\n```\n\n**What It Does:**\n1. Runs full static NLP analysis on ALL files\n2. Updates `codex-index.json` and `codex-report.json`\n3. Creates a new branch: `catalog/full-reindex-{timestamp}`\n4. Commits changes\n5. Pushes to GitHub\n6. **Creates a PR** (requires manual approval by default)\n7. Optionally auto-merges if `AUTO_CATALOG_MERGE=true`\n\n**Options:**\n\n```bash\n# Dry run (see what would change, no PR)\n./scripts/retrigger-full-catalog.sh --dry-run\n\n# Force auto-merge (overrides AUTO_CATALOG_MERGE setting)\n./scripts/retrigger-full-catalog.sh --auto-merge\n```\n\n**Requirements:**\n- `GH_PAT` environment variable (for PR creation)\n- Git configured with user name/email\n\n**Cost:** $0 (static NLP only)\n\n---\n\n## Method 3: Manual Local Re-Index\n\nFor testing or local development:\n\n```bash\ncd apps/codex\nnpm install\nnpm run index -- --validate\n```\n\n**Output Files:**\n- `codex-index.json` - Full searchable index\n- `codex-report.json` - Analytics and validation report\n\n**To Deploy:**\n```bash\ngit add codex-index.json codex-report.json\ngit commit -m \"chore: manual re-index\"\ngit push\n```\n\n---\n\n## Auto-Merge Configuration\n\n### Default Behavior: Manual Approval Required\n\nBy default, full re-catalog PRs require **manual review and approval**. This is the recommended setting to catch any unexpected metadata changes.\n\n### Enable Auto-Merge\n\nSet this GitHub secret to enable automatic merging:\n\n```bash\nAUTO_CATALOG_MERGE=true\n```\n\n**When enabled:**\n- Re-catalog PRs will auto-merge after validation passes\n- No human review required\n- Faster iteration, but less oversight\n\n**When to enable:**\n- High trust in automation\n- Frequent re-catalogs needed\n- Well-tested vocabulary and schema\n\n**When to keep disabled (recommended):**\n- Initial setup phase\n- Testing new categorization rules\n- Want to review metadata changes\n- Prefer human oversight\n\n### Toggle via Script\n\n```bash\n# With auto-merge\nAUTO_CATALOG_MERGE=true ./scripts/retrigger-full-catalog.sh\n\n# Without auto-merge (default)\n./scripts/retrigger-full-catalog.sh\n\n# Force auto-merge (one-time override)\n./scripts/retrigger-full-catalog.sh --auto-merge\n```\n\n---\n\n## What Gets Updated\n\n### Static NLP Analysis (Always Runs)\n\n1. **Keywords Extraction** (TF-IDF)\n   - Identifies most important terms\n   - Filters stop words\n   - Ranks by relevance\n\n2. **Phrase Detection** (N-grams)\n   - Finds common 2-3 word phrases\n   - Identifies repeated patterns\n   - Suggests tags\n\n3. **Category Matching**\n   - Matches against controlled vocabulary\n   - Assigns subjects and topics\n   - Calculates confidence scores\n\n4. **Difficulty Detection**\n   - Heuristic analysis of complexity indicators\n   - Keyword-based classification\n   - Assigns beginner/intermediate/advanced/expert\n\n5. **Summary Generation**\n   - Extractive summarization\n   - Picks most representative sentence\n   - Truncates to 300 characters\n\n6. **Validation**\n   - Schema compliance\n   - Required fields check\n   - Content quality rules\n   - Duplicate detection\n\n### What Does NOT Get Updated\n\nâŒ **Manual metadata is preserved:**\n- Explicitly set titles, summaries, tags\n- User-defined relationships\n- Custom categorization\n- Version numbers\n- Author information\n\nâœ… **Only auto-generated fields are updated:**\n- `metadata.autoGenerated.*`\n- Missing fields (if not explicitly set)\n- Validation warnings/suggestions\n\n---\n\n## Reviewing Re-Catalog PRs\n\n### What to Check\n\n1. **Metadata Changes**\n   - Are auto-tags accurate?\n   - Is difficulty le",
    "searchText": "frame codex re-catalog guide complete guide to triggering full re-indexing and metadata updates for all frame codex content catalog run retrigger validation report merge index full changes monthly avg review prs check codex full catalog auto merge scripts retrigger retrigger full codex report report json static nlp frame codex codex index index json"
  },
  {
    "path": "docs/contributing/how-to-submit.md",
    "name": "how-to-submit.md",
    "type": "file",
    "metadata": {
      "id": "how-to-submit-guide",
      "slug": "how-to-submit",
      "title": "How to Submit to Frame Codex",
      "summary": "Complete guide to contributing knowledge to Frame Codex using the submission UI, GitHub, or manual PR creation",
      "version": "1.0.0",
      "contentType": "markdown",
      "difficulty": "beginner",
      "taxonomy": {
        "subjects": [
          "knowledge",
          "technology"
        ],
        "topics": [
          "getting-started",
          "best-practices"
        ]
      },
      "tags": [
        "contributing",
        "submission",
        "guide",
        "tutorial"
      ],
      "publishing": {
        "created": "2025-01-15T00:00:00Z",
        "status": "published"
      },
      "autoGenerated": {
        "keywords": [
          "recursion",
          "submission",
          "submissions",
          "direct",
          "content",
          "modal",
          "field",
          "uuidgenerator",
          "net",
          "discord",
          "token",
          "contribution",
          "github",
          "submit",
          "add"
        ],
        "phrases": [
          "frame dev",
          "frame codex",
          "dev codex",
          "add content",
          "github com",
          "framersai codex",
          "content title",
          "content analysis",
          "create pull",
          "pull request"
        ],
        "subjects": [
          "knowledge",
          "technology"
        ],
        "topics": [
          "getting-started",
          "best-practices"
        ],
        "difficulty": "beginner",
        "confidence": {},
        "readingLevel": 0,
        "readabilityScore": 0,
        "statistics": {},
        "entities": {
          "people": [
            "PAT,",
            "PAT",
            "PAT** (Optional)"
          ],
          "places": [
            "**Preview"
          ],
          "organizations": [
            "GitHub",
            "Direct GitHub",
            "**GitHub",
            "GitHub",
            "**Provide GitHub",
            "GitHub",
            "GitHub",
            "GitHub",
            "GitHub",
            "PR"
          ],
          "topics": [
            "GitHub",
            "GitHub",
            "External resources",
            "PR",
            "GitHub",
            "GitHub",
            "GitHub",
            "GitHub",
            "**Provide GitHub",
            "GitHub",
            "**GitHub",
            "Direct GitHub",
            "GitHub",
            "**Preview",
            "PAT** (Optional)"
          ]
        },
        "lastIndexed": "2025-12-01T07:58:13.113Z"
      }
    },
    "validation": {
      "valid": true,
      "errors": [],
      "warnings": [],
      "suggestions": [
        "Consider adding relationships (requires, references, seeAlso)",
        "Key phrases found: frame dev, frame codex, dev codex"
      ]
    },
    "content": "\n# How to Submit to Frame Codex\n\nWelcome! This guide will walk you through the different ways to contribute knowledge to Frame Codex.\n\n## Quick Start\n\nThe easiest way to submit content is through our **enhanced contribution modal** at [frame.dev/codex](https://frame.dev/codex):\n\n1. Click the green **\"Contribute\"** button in the Codex viewer toolbar\n2. Fill in your content (title, summary, markdown body)\n3. Specify or leave blank weave/loom for AI suggestion\n4. Add tags (or use suggested tags from content analysis)\n5. Choose difficulty level (beginner/intermediate/advanced/expert)\n6. Toggle AI enhancement (optional, explains cost vs free static NLP)\n7. Preview final markdown with frontmatter\n8. Click **\"Create Pull Request\"** (uses GitHub API if you provide PAT, or opens GitHub editor)\n\nThat's it! Our automated validation runs, and maintainers review your submission.\n\n---\n\n## Submission Methods\n\n### Method 1: Web Submission UI (Recommended)\n\n**Best for:** Quick submissions, beginners, anyone without Git expertise\n\nThe enhanced contribution modal provides:\n- âœ… Pre-filled metadata based on current context\n- âœ… Tag suggestions from content analysis\n- âœ… Weave/loom inference (or manual override)\n- âœ… AI enhancement toggle (optional, cost-transparent)\n- âœ… Direct GitHub PR creation via API\n- âœ… Fallback to GitHub web editor (no PAT required)\n- âœ… Preview step showing final markdown\n- âœ… No local setup required\n\n**Steps:**\n\n1. **Open Contribution Modal**\n   - Go to [frame.dev/codex](https://frame.dev/codex)\n   - Click the green \"Contribute\" button in the toolbar\n   - Or use quick actions dropdown (mobile)\n\n2. **Fill in Content**\n   - **Title**: Clear, descriptive title (required)\n   - **Summary**: 20-300 character abstract (required)\n   - **Content**: Write or paste markdown (minimum 100 characters, required)\n\n3. **Specify Location** (Optional - AI can suggest if left blank)\n   - **Weave**: Which knowledge universe (e.g., technology, science, community)\n   - **Loom**: Topic collection (e.g., programming, algorithms)\n   - System auto-detects from current path or suggests based on content\n\n4. **Add Metadata**\n   - **Tags**: Type and press Enter, or click suggested tags from content analysis\n   - **Difficulty**: Select beginner/intermediate/advanced/expert\n   - **Subjects/Topics**: Auto-suggested from controlled vocabulary\n\n5. **AI Enhancement** (Optional)\n   - Toggle ON: AI analyzes content, suggests better categorization (~$0.01-0.20 cost)\n   - Toggle OFF: Static NLP only (free, still provides quality validation)\n\n6. **GitHub PAT** (Optional)\n   - Provide token for direct API PR creation\n   - Token is used only in your browser to call GitHub APIs directly and is never stored in localStorage, IndexedDB, SQL, or on any Frame.dev server\n   - Leave blank to open GitHub web editor instead\n\n7. **Preview & Submit**\n   - Review generated markdown with frontmatter\n   - See final file path: `weaves/{weave}/{loom}/{slug}.md`\n   - Click \"Create Pull Request\"\n     - Summary (extractive summarization)\n     - Tags (TF-IDF keyword extraction)\n     - Difficulty level (heuristic detection)\n     - Subjects and topics (vocabulary matching)\n   - Edit any field as needed\n\n4. **Provide GitHub Token**\n   - Create a [Personal Access Token](https://github.com/settings/tokens/new?scopes=repo&description=Frame%20Codex%20Submission) with `repo` scope\n   - Paste it into the token field in the Frame Codex UI\n   - The token lives only in that browser tabâ€™s memory while the modal is open, is never persisted in local storage / IndexedDB / SQL, and is sent only to GitHub (never to any Frame.dev backend)\n\n5. **Submit**\n   - Click \"Create Pull Request\"\n   - A new PR will be created on GitHub\n   - You'll receive a link to track the review\n\n**Rate Limits:**\n- 5 submissions per hour per user\n- Resets automatically after 60 minutes\n\n---\n\n### Method 2: GitHub Direct (Advanced)\n\n**Best for:** Bulk submissions, complex content, experienced contributors\n\n**Steps:**\n\n1. **Fork the Repository**\n   ```bash\n   gh repo fork framersai/codex --clone\n   cd codex\n   ```\n\n2. **Create a Branch**\n   ```bash\n   git checkout -b add-my-content\n   ```\n\n3. **Add Your Content**\n   - Place files directly within the target weave. Any folder becomes a loom, and any markdown file becomes a strand:\n     ```\n     weaves/\n       [weave-name]/\n         weave.yaml\n         overview.md                 # Strand at weave root\n         [loom-folder]/              # e.g. guides/, research/, notes/\n           loom.yaml (optional)\n           your-content.md\n           nested/topic/advanced.md  # Nested looms are allowed\n     ```\n   - See [submission-schema.md](./submission-schema.md) for required metadata\n\n4. **Validate Locally**\n   ```bash\n   npm install\n   npm run validate\n   npm run index -- --validate\n   ```\n\n5. **Commit and Push**\n   ```bash\n   git add .\n   git commit -m \"feat: add [your content title]\"\n   git push origin add-my-content\n   ```\n\n6. **Create Pull Request**\n   ```bash\n   gh pr cre",
    "searchText": "how to submit to frame codex complete guide to contributing knowledge to frame codex using the submission ui, github, or manual pr creation recursion submission submissions direct content modal field uuidgenerator net discord token contribution github submit add frame dev frame codex dev codex add content github com framersai codex content title content analysis create pull pull request"
  },
  {
    "path": "docs/contributing/submission-schema.md",
    "name": "submission-schema.md",
    "type": "file",
    "metadata": {
      "id": "submission-schema-reference",
      "slug": "submission-schema",
      "title": "Frame Codex Submission Schema Reference",
      "summary": "Complete technical reference for Frame Codex content schema, including all fields, validation rules, and OpenStrand ECA integration",
      "version": "2.0.0",
      "contentType": "markdown",
      "difficulty": "intermediate",
      "taxonomy": {
        "subjects": [
          "technology",
          "knowledge"
        ],
        "topics": [
          "api-reference",
          "architecture"
        ]
      },
      "tags": [
        "schema",
        "metadata",
        "yaml",
        "validation",
        "eca",
        "openstrand"
      ],
      "relationships": {
        "requires": [
          "how-to-submit"
        ],
        "references": [
          "openstrand-architecture"
        ]
      },
      "publishing": {
        "created": "2025-01-15T00:00:00Z",
        "status": "published"
      },
      "autoGenerated": {
        "keywords": [
          "string",
          "array",
          "enum",
          "iso",
          "8601",
          "computer",
          "programming",
          "fields",
          "recursion",
          "eca",
          "python",
          "functions",
          "15t00",
          "validation",
          "yaml"
        ],
        "phrases": [
          "array string",
          "array object",
          "string iso",
          "frame codex",
          "iso 8601",
          "computer science",
          "2025 15t00",
          "15t00 00z",
          "fields yaml",
          "object string"
        ],
        "subjects": [
          "technology",
          "knowledge"
        ],
        "topics": [
          "api-reference",
          "architecture"
        ],
        "difficulty": "intermediate",
        "confidence": {},
        "readingLevel": 0,
        "readabilityScore": 0,
        "statistics": {},
        "entities": {
          "people": [
            "[alice,",
            "bob]",
            "- Skip"
          ],
          "places": [
            "peer_review]",
            "peerReview:",
            "peerReview:"
          ],
          "organizations": [
            "Learning Design",
            "\"Abelson & Sussman,",
            "External resources",
            "- **GitHub"
          ],
          "topics": [
            "- **GitHub",
            "External resources",
            "\"Abelson & Sussman,",
            "Learning Design",
            "peerReview:",
            "peerReview:",
            "peer_review]",
            "- Skip",
            "bob]",
            "[alice,"
          ]
        },
        "lastIndexed": "2025-12-01T07:58:15.179Z"
      }
    },
    "validation": {
      "valid": true,
      "errors": [],
      "warnings": [],
      "suggestions": [
        "Key phrases found: array string, array object, string iso"
      ]
    },
    "content": "\n# Frame Codex Submission Schema Reference\n\nThis document provides the complete technical specification for Frame Codex content schema, including integration with OpenStrand's Educational Content Atom (ECA) standard.\n\n---\n\n## Table of Contents\n\n1. [Schema Overview](#schema-overview)\n2. [Strand Schema (Individual Content)](#strand-schema)\n3. [Loom Schema (Collections)](#loom-schema)\n4. [Weave Schema (Universes)](#weave-schema)\n5. [ECA Integration](#eca-integration)\n6. [Validation Rules](#validation-rules)\n7. [Examples](#examples)\n\n---\n\n## Schema Overview\n\nFrame Codex uses a three-tier knowledge organization:\n\n```\nWeave (Universe)\nâ”œâ”€â”€ Loom (Collection)\nâ”‚   â”œâ”€â”€ Strand (Content)\nâ”‚   â”œâ”€â”€ Strand (Content)\nâ”‚   â””â”€â”€ ...\nâ”œâ”€â”€ Loom (Collection)\nâ”‚   â””â”€â”€ ...\nâ””â”€â”€ ...\n```\n\n### Key Principles\n\n- **Strands** are atomic, self-contained knowledge units\n- **Looms** curate related strands into coherent learning paths\n- **Weaves** represent complete, isolated knowledge universes\n- **No cross-weave relationships** (each weave is independent)\n- **Subfolders are SUBTOPICS** - folder depth determines topic specificity (deeper = more specific)\n- **Topics are hierarchical** - must narrow scope as you go deeper in the folder tree\n- **Tags are independent** - can be shared freely across any folder level\n\n---\n\n## Strand Schema\n\nStrands are individual markdown files with YAML frontmatter.\n\n### Required Fields\n\n```yaml\nid: string (UUID v4)\nslug: string (lowercase, hyphens, alphanumeric)\ntitle: string (3-100 characters)\nsummary: string (20-300 characters)\nversion: string (semver: x.y.z)\ncontentType: enum [markdown, code, data, media]\ndifficulty: enum [beginner, intermediate, advanced, expert]\n```\n\n### Recommended Fields\n\n```yaml\ntaxonomy:\n  subjects: array<string>          # High-level categories\n  topics: array<string>            # âš ï¸ MUST match folder depth (see below)\n  subtopics: array<string>         # Even more specific narrowing\n  concepts: array<object>\n    - term: string\n      weight: number (0-1)\n      definition: string (optional)\n  skills: array<object>\n    - name: string\n      level: enum [introduce, develop, master]\n\ntags: array<string>               # âœ“ Independent - NO hierarchy\n\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n# âš ï¸  CRITICAL: Topics vs Tags\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n# \n# TOPICS are HIERARCHICAL:\n#   - Subfolders = subtopics of parent folder\n#   - Topics MUST become MORE SPECIFIC as folder depth increases\n#   - A file in /programming/python/async/ must have topics about async Python\n#   - NOT broad topics like \"web-development\"\n#\n# TAGS are INDEPENDENT:\n#   - No hierarchy, flat structure\n#   - Can be shared across ANY folder level\n#   - A deeply nested file can share tags with root files\n#   - Example: both /python/async/coroutines.md and /overview.md can use\n#     the tag \"best-practices\"\n#\n# See: openstrand-architecture.md#hierarchical-topic-structure-critical-rule\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n\nrelationships:\n  requires: array<string> (slugs of prerequisite strands)\n  references: array<string> (slugs of related strands)\n  seeAlso: array<string> (external URLs)\n\npublishing:\n  created: string (ISO 8601 datetime)\n  updated: string (ISO 8601 datetime)\n  status: enum [draft, review, published, archived]\n  license: string (default: CC-BY-4.0)\n  authors: array<string>\n```\n\n### OpenStrand ECA Extended Fields\n\nFrame Codex supports the full OpenStrand Educational Content Atom (ECA) specification for advanced learning design:\n\n```yaml\n# Learning Design\nlearningDesign:\n  objectives: array<object>\n    - id: string\n      description: string\n      bloomsLevel: enum [remember, understand, apply, analyze, evaluate, create]\n      measurable: boolean\n  \n  outcomes: array<object>\n    - id: string\n      description: string\n      assessment: string (optional)\n  \n  pedagogicalApproach: array<enum>\n    # Options: direct_instruction, discovery_learning, problem_based,\n    #          collaborative, experiential, inquiry_based\n  \n  instructionalStrategies: array<string>\n\n# Time Estimates\ntimeEstimates:\n  reading: number (minutes)\n  exercises: number (minutes)\n  projects: number (minutes)\n  total: number (minutes)\n\n# Modality Support\nmodalities:\n  text: boolean\n  visual:\n    diagrams: number\n    images: number\n    charts: number\n  audio:\n    narration: boolean\n    duration: number (seconds, optional)\n  video:\n    embedded: number\n    duration: number (seconds, optional)\n  kinesthetic:\n    simulations: number\n    exercises: number\n\n# Interactive Elements\ninteractiveElements: array<object>\n  - id: string\n    type: enum [quiz, poll, simulation, code_exercise, discussion_prompt, reflection, peer_review]\n    required: boolean\n    data: object (type-specific)\n\n# Assessment\nassessments:\n  formative: array<object>\n    - id: string\n      type: string\n      weight: number (0-1)\n  summative: array<object>\n    - id: string\n      type: s",
    "searchText": "frame codex submission schema reference complete technical reference for frame codex content schema, including all fields, validation rules, and openstrand eca integration string array enum iso 8601 computer programming fields recursion eca python functions 15t00 validation yaml array string array object string iso frame codex iso 8601 computer science 2025 15t00 15t00 00z fields yaml object string"
  },
  {
    "path": "docs/openstrand-architecture.md",
    "name": "openstrand-architecture.md",
    "type": "file",
    "metadata": {
      "id": "openstrand-architecture-overview",
      "slug": "openstrand-architecture",
      "title": "OpenStrand Architecture Overview",
      "summary": "Comprehensive guide to OpenStrand's knowledge infrastructure, explaining how Weaves, Looms, and Strands work together to create the foundation for Frame Codex",
      "version": "1.0.0",
      "contentType": "markdown",
      "difficulty": "intermediate",
      "taxonomy": {
        "subjects": [
          "technology",
          "ai",
          "knowledge"
        ],
        "topics": [
          "architecture",
          "getting-started"
        ]
      },
      "tags": [
        "openstrand",
        "architecture",
        "knowledge-graph",
        "weave",
        "loom",
        "strand"
      ],
      "relationships": {
        "references": [
          "frame-codex-intro",
          "schema-reference"
        ],
        "seeAlso": [
          "https://openstrand.ai",
          "https://frame.dev"
        ]
      },
      "publishing": {
        "created": "2025-01-15T00:00:00.000Z",
        "updated": "2025-01-15T00:00:00.000Z",
        "status": "published"
      },
      "autoGenerated": {
        "keywords": [
          "infrastructure",
          "async",
          "python",
          "programming",
          "coroutines",
          "weaves",
          "fabric",
          "topics",
          "technology",
          "openstrand",
          "topic",
          "knowledge",
          "hierarchy",
          "depth",
          "immutable"
        ],
        "phrases": [
          "frame codex",
          "weaves technology",
          "best practices",
          "programming python",
          "python async",
          "frame dev",
          "markdown file",
          "technology programming",
          "knowledge graph",
          "openstrand architecture"
        ],
        "subjects": [
          "technology",
          "ai",
          "knowledge"
        ],
        "topics": [
          "architecture",
          "getting-started"
        ],
        "difficulty": "intermediate",
        "confidence": {},
        "readingLevel": 0,
        "readabilityScore": 0,
        "statistics": {},
        "entities": {
          "people": [
            "- **Rich"
          ],
          "places": [],
          "organizations": [
            "- **GitHub",
            "LLM service,"
          ],
          "topics": [
            "LLM service,",
            "- **GitHub",
            "- **Rich"
          ]
        },
        "lastIndexed": "2025-12-01T07:58:16.543Z"
      }
    },
    "validation": {
      "valid": true,
      "errors": [],
      "warnings": [],
      "suggestions": [
        "Key phrases found: frame codex, weaves technology, best practices"
      ]
    },
    "content": "\n# OpenStrand Architecture Overview\n\nOpenStrand is the knowledge infrastructure that powers Frame.dev and Frame Codex. It provides a structured, AI-native way to organize, store, and retrieve humanity's knowledge.\n\n## Core Concepts\n\n### The Four-Tier Hierarchy\n\nOpenStrand organizes knowledge using four fundamental primitives:\n\n**Fabric** - A collection of weaves\n- The highest level of organization\n- Represents an entire knowledge repository or ecosystem\n- Example: Frame Codex itself is a fabric\n- Contains multiple weaves that are conceptually related but independent\n\n**Strand** - The atomic unit of knowledge\n- A single document, image, dataset, or media file\n- Contains rich metadata for categorization and discovery\n- Can reference other strands within the same weave\n- Immutable once published (new versions create new strands)\n\n**Loom** - A curated collection of related strands\n- Groups strands by topic, theme, or learning path\n- Defines ordering (sequential, hierarchical, or network)\n- Provides context and relationships between strands\n- Acts as a module or chapter in the knowledge base\n\n**Weave** - A complete universe of knowledge\n- Self-contained collection with no external dependencies\n- Represents a domain, project, or knowledge area\n- No relationships exist between different weaves\n- Think of it as a separate universe or dimension\n\n### Why This Structure?\n\nThe Fabric/Weave/Loom/Strand architecture solves several key problems:\n\n1. **Isolation**: Weaves are completely independent, preventing knowledge pollution\n2. **Scalability**: Each weave can grow infinitely without affecting others\n3. **Clarity**: Clear boundaries make it obvious where knowledge belongs\n4. **Versioning**: Strands are immutable, making version control natural\n5. **AI-Friendly**: Structured metadata enables semantic search and RAG\n6. **Fabric-Scope Reasoning**: A single Fabric view allows cross-weave synthesis while preserving provenance\n\n### Superintelligence at Fabric Scope\n\nWhile weaves remain isolated for organization and provenance, analysis at the **Fabric** level permits traversal\nacross weaves for:\n\n- Cross-domain retrieval and context assembly\n- Whole-of-corpus synthesis and summarization\n- Global topic maps and knowledge graphs\n\nFabric-level queries always preserve original weave/loom/strand provenance. OpenStrand uses this fabric view to let\nagents and superintelligence move seamlessly across domains while still understanding exactly where every fact came from.\n\n## How It Works\n\n### Knowledge Flow\n\n```\nFabric (Repository)\n  â””â”€â”€ Weave (Universe)\n        â””â”€â”€ Loom (Collection / any subdirectory)\n              â”œâ”€â”€ Strand (Markdown file)\n              â”œâ”€â”€ Strand (Markdown file)\n              â””â”€â”€ Loom (Nested subdirectory)\n                    â””â”€â”€ Strand (Markdown file)\n```\n\n### Example: Frame Ecosystem Weave\n\n```yaml\n# weaves/frame/weave.yaml\nslug: frame\ntitle: Frame.dev Ecosystem\ndescription: Complete knowledge base for Frame products and infrastructure\n```\n\nThis weave contains looms for:\n- OpenStrand documentation\n- AgentOS guides\n- Frame API reference\n- Architecture patterns\n\nğŸ’¡ **Physical layout**: Loosely structured folders â€” no `looms/` or `strands/` prefixes are required.\n\n```\nweaves/frame/\nâ”œâ”€â”€ weave.yaml\nâ”œâ”€â”€ overview.md\nâ”œâ”€â”€ openstrand/\nâ”‚   â”œâ”€â”€ loom.yaml\nâ”‚   â””â”€â”€ architecture.md\nâ””â”€â”€ guides/agentos/deployment.md\n```\n\nEach folder inside `weaves/frame/` is treated as a loom, and every markdown file (at any depth) is a strand that can reference other strands.\n\n### Hierarchical Topic Structure (Critical Rule)\n\n**Folder depth determines topic specificity.** This is a fundamental OpenStrand principle:\n\n> ğŸ“ **Subfolders are SUBTOPICS of their parent folder. Topics MUST become more specific as you go deeper.**\n\n#### How It Works\n\n```\nweaves/technology/                     # Topic: technology (broad)\nâ”œâ”€â”€ programming/                       # Topic: programming (more specific)\nâ”‚   â”œâ”€â”€ python/                        # Topic: python (even more specific)\nâ”‚   â”‚   â””â”€â”€ async/                     # Topic: async-python (most specific)\nâ”‚   â”‚       â””â”€â”€ coroutines.md          # Strand about Python coroutines\nâ”‚   â””â”€â”€ rust/                          # Topic: rust (sibling to python)\nâ”‚       â””â”€â”€ memory-safety.md\nâ””â”€â”€ infrastructure/                    # Topic: infrastructure (sibling to programming)\n    â””â”€â”€ kubernetes/\n        â””â”€â”€ networking.md\n```\n\n**The hierarchy implies:**\n- `programming/` is a subtopic of `technology/`\n- `python/` is a subtopic of `programming/`\n- `async/` is a subtopic of `python/`\n- Content in `async/` MUST be about async Python, not general async concepts\n\n#### Topics vs Tags: The Critical Distinction\n\n| Aspect | **Topics** (Hierarchical) | **Tags** (Independent) |\n|--------|---------------------------|------------------------|\n| Structure | Tree-like, parent-child | Flat, no hierarchy |\n| Inheritance | Child topics MUST narrow parent scope | No inheritance |\n| Sharing | Cannot share across unrelated branches | Can share across",
    "searchText": "openstrand architecture overview comprehensive guide to openstrand's knowledge infrastructure, explaining how weaves, looms, and strands work together to create the foundation for frame codex infrastructure async python programming coroutines weaves fabric topics technology openstrand topic knowledge hierarchy depth immutable frame codex weaves technology best practices programming python python async frame dev markdown file technology programming knowledge graph openstrand architecture"
  },
  {
    "path": "docs/schema-reference.md",
    "name": "schema-reference.md",
    "type": "file",
    "metadata": {
      "id": "schema-reference-guide",
      "slug": "schema-reference",
      "title": "Frame Codex Schema Reference",
      "summary": "Complete reference for Weave, Loom, and Strand schemas with examples and validation rules",
      "version": "1.0.0",
      "contentType": "markdown",
      "difficulty": "intermediate",
      "taxonomy": {
        "subjects": [
          "technology"
        ],
        "topics": [
          "api-reference",
          "architecture"
        ]
      },
      "tags": [
        "schema",
        "yaml",
        "validation",
        "weave",
        "loom",
        "strand"
      ],
      "relationships": {
        "references": [
          "openstrand-architecture"
        ]
      },
      "publishing": {
        "created": "2025-01-15T00:00:00.000Z",
        "updated": "2025-01-15T00:00:00.000Z",
        "status": "published"
      },
      "autoGenerated": {
        "keywords": [
          "string",
          "array",
          "fields",
          "openstrand",
          "identifier",
          "url",
          "topics",
          "enum",
          "template",
          "reference",
          "unique",
          "controlled",
          "npm",
          "valid",
          "comprehensive"
        ],
        "phrases": [
          "openstrand architecture",
          "controlled vocabulary",
          "frame dev",
          "npm run",
          "frame codex",
          "schema reference",
          "required fields",
          "slug string",
          "unique identifier",
          "title string"
        ],
        "subjects": [
          "technology"
        ],
        "topics": [
          "api-reference",
          "architecture"
        ],
        "difficulty": "intermediate",
        "confidence": {},
        "readingLevel": 0,
        "readabilityScore": 0,
        "statistics": {},
        "entities": {
          "people": [],
          "places": [],
          "organizations": [],
          "topics": []
        },
        "lastIndexed": "2025-12-01T07:58:17.536Z"
      }
    },
    "validation": {
      "valid": true,
      "errors": [],
      "warnings": [],
      "suggestions": [
        "Key phrases found: openstrand architecture, controlled vocabulary, frame dev"
      ]
    },
    "content": "\n# Frame Codex Schema Reference\n\nThis document provides the complete schema reference for all Frame Codex content types.\n\n## Weave Schema\n\nA Weave represents a complete, self-contained universe of knowledge.\n\n### Required Fields\n\n- `slug` (string): Unique identifier, lowercase with hyphens\n- `title` (string): Human-readable name\n- `description` (string): Comprehensive description\n\n### Optional Fields\n\n- `maintainedBy` (object): Maintainer information\n  - `name` (string): Name of person or organization\n  - `url` (string): Contact or website URL\n- `license` (string): Content license (default: MIT)\n- `tags` (array): Categorization tags from controlled vocabulary\n\n### Example\n\n```yaml\nslug: frame\ntitle: Frame.dev Ecosystem\ndescription: Comprehensive knowledge base for Frame.dev products and infrastructure\nmaintainedBy:\n  name: Frame.dev Team\n  url: https://frame.dev\nlicense: MIT\ntags:\n  - technology\n  - ai-infrastructure\n  - superintelligence\n```\n\n## Loom Schema\n\nA Loom is a curated collection of related strands within a weave.\n\n### Required Fields\n\n- `slug` (string): Unique identifier within the weave\n- `title` (string): Display title\n- `summary` (string): Brief description\n\n### Optional Fields\n\n- `tags` (array): Subject tags for categorization\n- `ordering` (object): How strands are organized\n  - `type` (enum): `sequential`, `hierarchical`, or `network`\n  - `items` (array): Ordered list of strand slugs\n\n### Example\n\n```yaml\nslug: getting-started\ntitle: Getting Started with Frame\nsummary: Essential guides and tutorials for new Frame developers\ntags:\n  - tutorial\n  - beginner\nordering:\n  type: sequential\n  items:\n    - installation\n    - hello-world\n    - core-concepts\n    - first-project\n```\n\n## Strand Schema\n\nA Strand is an atomic unit of knowledge - a document, image, or dataset.\n\n### Required Fields\n\n- `id` (string): Globally unique identifier (UUID)\n- `slug` (string): URL-friendly identifier\n- `title` (string): Display title\n\n### Optional Fields\n\n- `summary` (string): Brief abstract (recommended for search)\n- `version` (string): Semantic version (default: 1.0.0)\n- `contentType` (enum): `markdown`, `code`, `data`, or `media`\n- `difficulty` (enum): `beginner`, `intermediate`, `advanced`, or `expert`\n- `taxonomy` (object): Categorization\n  - `subjects` (array): High-level categories\n  - `topics` (array): Specific topics **âš ï¸ MUST match folder depth - see note below**\n- `tags` (array): Freeform tags **âœ“ Independent - can be shared across any level**\n\n> **âš ï¸ Topics vs Tags**: Topics are HIERARCHICAL and must become MORE SPECIFIC as folder depth increases. Tags are INDEPENDENT and can be freely shared. See [Hierarchical Topic Structure](./openstrand-architecture.md#hierarchical-topic-structure-critical-rule).\n- `relationships` (object): Connections to other strands\n  - `requires` (array): Prerequisites\n  - `references` (array): Related strands\n  - `seeAlso` (array): External URLs\n- `publishing` (object): Publication metadata\n  - `created` (string): ISO 8601 timestamp\n  - `updated` (string): ISO 8601 timestamp\n  - `status` (enum): `draft`, `published`, `archived`\n\n### Example\n\n```yaml\n---\nid: 550e8400-e29b-41d4-a716-446655440000\nslug: openstrand-architecture\ntitle: OpenStrand Architecture Overview\nsummary: Comprehensive guide to OpenStrand's system architecture and design principles\nversion: 1.2.0\ncontentType: markdown\ndifficulty: intermediate\ntaxonomy:\n  subjects:\n    - technology\n    - ai\n  topics:\n    - architecture\n    - getting-started\ntags:\n  - openstrand\n  - architecture\n  - knowledge-graph\nrelationships:\n  requires:\n    - core-concepts\n  references:\n    - frame-codex-intro\n    - api-reference\n  seeAlso:\n    - https://openstrand.ai\n    - https://frame.dev\npublishing:\n  created: 2025-01-15T00:00:00Z\n  updated: 2025-01-15T00:00:00Z\n  status: published\n---\n\n# Your content here...\n```\n\n## Validation Rules\n\n### Slug Format\n\n- Lowercase letters, numbers, and hyphens only\n- No spaces or special characters\n- Must be unique within scope (weave/loom)\n\n### ID Format\n\n- Must be a valid UUID v4\n- Globally unique across all strands\n- Generate using `npm run generate-template`\n\n### Version Format\n\n- Semantic versioning: `MAJOR.MINOR.PATCH`\n- Example: `1.0.0`, `2.1.3`\n\n### Content Requirements\n\n- Minimum 100 characters of meaningful content\n- No unfinished sections or test content\n- Proper markdown formatting\n- Valid YAML frontmatter\n\n## Auto-Generated Metadata\n\nThe indexer automatically generates:\n\n- **Keywords**: Extracted using TF-IDF algorithm\n- **Phrases**: Common multi-word expressions\n- **Subjects**: Matched from controlled vocabulary\n- **Topics**: Detected from content analysis\n- **Difficulty**: Inferred from language complexity\n- **Summary**: Generated if missing\n\nYou can override any auto-generated values by specifying them explicitly in your frontmatter.\n\n## Controlled Vocabulary\n\nTags should use terms from the controlled vocabulary when possible:\n\n### Subjects\n- technology, science, philosophy, ai, knowledge, d",
    "searchText": "frame codex schema reference complete reference for weave, loom, and strand schemas with examples and validation rules string array fields openstrand identifier url topics enum template reference unique controlled npm valid comprehensive openstrand architecture controlled vocabulary frame dev npm run frame codex schema reference required fields slug string unique identifier title string"
  }
]